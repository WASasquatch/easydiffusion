{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WASasquatch/easydiffusion/blob/dev/Stability_AI_Easy_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y6RXjS1tTji"
      },
      "source": [
        "# Stability.AI Easy Diffusion v0.19 ![visitors](https://visitor-badge.glitch.me/badge?page_id=EasyDiffusion&left_color=blue&right_color=orange) [![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/WASasquatch/easydiffusion)\n",
        "\n",
        "Easy Diffusion was originally a fork of NOP's notebook, but has sort of evolved into it's own thing with many features. Such as depth output for 3D Facebook images, or post processing such as Depth of Field.\n",
        "\n",
        "If you'd like to help support the project and my time, feel free to buy me some bandwidth (I live rural and pay for bandwidth): https://paypal.me/ThompsonJordan\n",
        "\n",
        "<br>\n",
        "<hr>\n",
        "\n",
        "## <font color=\"default\">**Menu**</font>\n",
        "- <a href=\"#changelog\">**Change Log**</a>\n",
        "- <a href=\"#gpustatus\">**Check GPU Status**</a>\n",
        "- #### <a href=\"#setupenv\">**Setup Environment**</a>\n",
        " - <a href=\"#googledrive\">**Google Drive Options**</a>\n",
        " - <a href=\"#optionalfeats\">**Install Optional Features**</a>\n",
        " - <a href=\"#otherinstall\">**Other Install Options**</a>\n",
        "- #### <a href=\"#settingsdiffuse\">**Settings & Diffuse**</a>\n",
        " - <a href=\"#promptsetup\">**Prompt Setup**</a>\n",
        " - <a href=\"#initsetup\">**Init Image Setup**</a>\n",
        " - <a href=\"#diffusionsettings\">**Diffusion Settings**</a>\n",
        " - <a href=\"#upscalers\">**Upscaling Setup**</a>\n",
        " - <a href=\"#imageprocessors\">**Image Processing Setup**</a>\n",
        "   - <a href=\"#sharpen\">**Sharpen Image**</a>\n",
        "   - <a href=\"#kromo\">**Kromo Chromatic Aberration**</a>\n",
        "   - <a href=\"#median\">**Median Filter Image**</a>\n",
        "   - <a href=\"#midas\">**MiDaS Depth Export**</a>\n",
        "   - <a href=\"#fdof\">**Fake Depth of Field Filter**</a>\n",
        "   - <a href=\"#tileable\">**Tileable Seamless Image**</a>\n",
        " - <a href=\"#clipinterrogator\">**CLIP Interrogator**</a>\n",
        " - <a href=\"#othersettings\">**Other Diffusion Settings**</a>\n",
        "- <a href=\"#cleanenv\">**Clean Environment Up**</a>\n",
        "\n",
        "<br>\n",
        "<hr>\n",
        "\n",
        "## Stablity.AI Model Terms of Use\n",
        "\n",
        "**By using this Notebook, you agree to the following Terms of Use, and license**\n",
        "\n",
        "This model is open access and available to all, with a CreativeML OpenRAIL-M license further specifying rights and usage.\n",
        "\n",
        "The CreativeML OpenRAIL License specifies:\n",
        "1. You can't use the model to deliberately produce nor share illegal or harmful outputs or content\n",
        "2. CompVis claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license\n",
        "3. You may re-distribute the weights and use the model commercially and/or as a service. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully)\n",
        "\n",
        "Please read the full license here: https://huggingface.co/spaces/CompVis/stable-diffusion-license \n",
        "\n",
        "## Expand for Changelog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G76cGaiuGdjJ"
      },
      "source": [
        "\n",
        "\n",
        "## <a name=\"changelog\">Change Log</a>:\n",
        "- v0.1: Forked [NOP's Stable Diffusion Colab v0.23](https://colab.research.google.com/drive/1jUwJ0owjigpG-9m6AI_wEStwimisUE17?usp=sharing)\n",
        "  - Added File Prompts\n",
        "  - Added Noodle Soup Prompts\n",
        "- 8/25/2022) Added better image output display\n",
        "- 8/26/2022) Added `INIT_IMAGE` support\n",
        "  - Added basic image output option\n",
        "- 8/27/2022) Patched CodeFormer fidelity path bug\n",
        "- 8/27/2022) Various code tweaks (by plambe#5832)\n",
        "  - Download some of the dependencies to google drive if enabled \n",
        "    - For instance the stable diffusion model\n",
        "    - Also multiple of the git repos\n",
        "  - Replaced all `!` and `%` in code to make it more universal\n",
        "- 8/27/2022) Patch NSP Installation, changed paths for Stable Diffusion and output images. (by WAS#0263)\n",
        "- 8/27/2022) Organized and improved installations\n",
        "- 8/28/2022) Real-ESRGAN bug fix (by plambe#5832)\n",
        "- 8/28/2022) GFPGAN bug fix (by plambe#5832)\n",
        "- 8/28/2022) CodeFormer bug fix (by plambe#5832)\n",
        "- 8/28/2022) Added cached diffusion piping: This will speed up run performance (WAS#0263)\n",
        "  - Added `RECACHE_PIPES` option\n",
        "  - Added `INCREMENT_ITERATION_SEED` option\n",
        "  - Patched working directory path for non-gdrive installations\n",
        "  - Patched working directory path for pipe cache not found\n",
        "  - Patched CodeFormer Fidelity paths, again?\n",
        "  - Added pre-ESRGAN down scaling option for GFPGAN + Real-ESRGAN, and CodeFormer + Real-ESRGAN.\n",
        "  - Added post diffusion sharpen option\n",
        "- **V0.6** | 8/29/2022) Added optional cached pipes. Using cached pipes is best for a high VRAM environment\n",
        "  - Added Kromo's Chromatic Aberration\n",
        "  - Added Sharpening\n",
        "  - Added optional dependency installs (save some space!)\n",
        "- **v0.7** | 8/29/2022) Added MiDaS Depth Approximation\n",
        "  - Depth maps can be used to apply Depth of Field, or other filmic effects in post processing with your favorite tools.\n",
        "- **v0.8** | 8/30/2022) Added Sampling Schedulers\n",
        "  -  Track function timing\n",
        "  - 8/31/2022) Patch MiDaS Depth Export even when unchecked.\n",
        "- **v0.9** | 9/1/2022) Added multi-init functionality to `INIT_IMAGE`.\n",
        "  - `INIT_IMAGE` supports a local/remote image path/url, a txt file containing a path/url per line, or a path to a folder containing images.\n",
        "  - Add `ESRGAN_MODE` which allows you to run ESRGAN on CPU if you want to conserve more VRAM.\n",
        "  - Add `MIDAS_PERSISTENT` mode. Keep MiDaS models in memory between iterations.\n",
        "  - 9/2/2022) Patch Pillow<9.0.0 versions for Resampling calls.\n",
        "  - Prepare for model selection\n",
        "- **v0.10** | 9/3/2022) Added collapsible batches and iterations in organized JS image output mode (default behavior)\n",
        "  - Improved environment cleanup (again)\n",
        "  - Added ability to clear log between iterations. *This would clear the diffusion result before viewing it in standard mode, so is disabled for non JS image output*\n",
        "- 9/4/2022) Add ability to skip diffusion run. Useful for processing prior diffusions or inits with image filters and upscalers. \n",
        "- **v0.11** | 9/5/2022) Patched img2img pipeline\n",
        " - Added Median Filter\n",
        " - Added Fake Depth of Field\n",
        " - Added Tileable Seamless Texture outout (also supports seamless depth map if Export Depth Map is enabled)\n",
        " - Various code improvements.\n",
        "- **v0.12** | 9/6/2022) Overhaul of Easy Diffusion Setup Process\n",
        " -  Easily enable/disable NSFW checker per run, and now returns a blurred image instead of black image. \n",
        " - CodeFormer now has a seprate upscale param, which unfortuantely couldn't be a slider. But CodeFormer now supports 1x (no upscaling).\n",
        " - Patch image display for FDOF active mode. \n",
        "- **v0.13** | 9/7/2022) Added Attention Slices optimization. This feature splits the job into slices for better use of available VRAM. Use `ENABLE_ATTENTION_SLICES` in diffusion settings to try it out.\n",
        " - `LOW_VRAM_PATCH` can be toggled from diffusion settings for **non-cached** pipes. \n",
        " - Add ability to set `MAX_SEED` size. Either a custom integether or `'system_max'` (with semi-quotes).\n",
        " - Add text2seed ability. Seed is now a raw input, and you can input text like `'rockycanyon'` (with semi-quotes) which will be converted to textual equivalent. \n",
        "- **v0.14** | 9/8/2022) Added ability to save model to Google Drive if not using drive for local copies.\n",
        " - Add `CUSTOM_MODEL` path field. This will override the selected `MODEL_ID` if exists.\n",
        " - Pipelines have been overhauled and should be much lighter on memory (should be the same as a regular loaded pipe), and offer much faster load times.\n",
        "- **v0.15** | 9/10/2022) Added Menu's for quicker initial navigation. \n",
        " - Added Google Colab paramScraper for settings export. \n",
        "- **v0.16** | 9/11/2022) Added pharmapsychotic's CLIP Interrogator\n",
        " - Interrogate init images or diffusion result\n",
        " - Model options are now available under `MODEL_ID`\n",
        "- **v0.17** | 9/14/2022) Added `INIT_IMAGE` support\n",
        " - Added `RECURSIVE_EVOLUTION` support. Allows you to take a txt2img result straight to img2img for further evolution. Doesn't work well with low `INIT_SCALE` values. \n",
        "<br>\n",
        "- **v0.18** | 9/14/2022) Rebuilt `cache_pipes()` function. It now will only cache the type of pipe active, and return said pipe. This will save storage space by only caching the pipes you actually use. \n",
        " - Minor patching to non-cached pipes for recursive evolution. \n",
        "- 9/15/2022 ) Added `KEEP_ONLY_FINAL_IMAGE` flag under <a href=\"#imageprocessors\">Image Processing</a> to keep only the final upscaled or processed image.\n",
        " - Various small code patches.\n",
        " - Patch `displayJsImage()` function to support Chrome/Edge\n",
        "- **v0.19** | 9/20/2022) Added Negative Prompts and preset Styles.\n",
        " - Negative prompts can be used denoting a string at the *end* of your prompt with `--`. Example: `Positive prompt here --Negative prompt here`\n",
        " - Add `INIT_FILTER` to filter init images from init files or folders of images for specific keywords.\n",
        " - 9/21/2022) More styles added"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NOEF-K5F5db"
      },
      "source": [
        "# Easy Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ekR-LW6trWG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <a name=\"gpustatus\">Check GPU Status</a>\n",
        "#@markdown Check the status of the allocated GPU\n",
        "import subprocess\n",
        "print(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "nvidiasmi_simple = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "gpu_name = nvidiasmi_simple.split(':')[1].split('(')[0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8gV4-qRDn1b",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <a name=\"setupenv\"><font size=\"5\" color=\"default\">**Setup Environment**</font></a>\n",
        "\n",
        "# Import future print\n",
        "from __future__ import print_function\n",
        "try:\n",
        "    import __builtin__\n",
        "except ImportError:\n",
        "    import builtins as __builtin__\n",
        "\n",
        "# Emoticon fun!\n",
        "import subprocess\n",
        "try:\n",
        "    import emoji\n",
        "except ImportError:\n",
        "     multipip_res = subprocess.run(['pip', '-q', 'install', 'emoji'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "finally:\n",
        "    import emoji\n",
        "\n",
        "print(subprocess.run('python -m ensurepip --upgrade'.split(' '), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "\n",
        "# Override Print Function\n",
        "def print(message, *args, **kwargs):\n",
        "    if 'defaultprint' in kwargs:\n",
        "        kwargs.pop('defaultprint')\n",
        "        return __builtin__.print(message, *args, **kwargs)\n",
        "    else:\n",
        "        return __builtin__.print(emoji.emojize(message), *args, **kwargs)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### <a name=\"googledrive\">**Google Drive Options**</a>\n",
        "USE_DRIVE_FOR_PICS = True #@param {type:\"boolean\"}\n",
        "#@markdown <font size=\"3\">Use Google Drive to store images and prompt information</font>\n",
        "USE_DRIVE_FOR_LOCAL_COPIES = False #@param {type:\"boolean\"}\n",
        "#@markdown <font size=\"3\">Use Google Drive to store local copies of git repos, models and other assets</font><br>\n",
        "#@markdown <font size=\"3\" color=\"orange\">**WARNING:**</font> Requires 14gb+ of space (not including images produced). May not be suitable for Free Google Drive accounts.</font><br>\n",
        "#@markdown <font size=\"3\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you encounter issues loading pipes, or Upscalers, you're likely out of storage space.</font>\n",
        "USE_DRIVE_FOR_MODELS = False #@param{type:'boolean'}\n",
        "#@markdown Use Google Drive for storing Stable Diffusion models. Only applicable if `USE_DRIVE_FOR_LOCAL_COPIES` is `False`.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### <a name=\"optionalfeats\">**Install Optional Features**</a>\n",
        "INSTALL_GFPGAN = True #@param{type:'boolean'}\n",
        "#@markdown <font size=\"3\">Install GFPGAN Face Enhancement</font>\n",
        "INSTALL_CODEFORMER = True #@param{type:'boolean'}\n",
        "#@markdown <font size=\"3\">Install CodeFormer Face Enhancement</font>\n",
        "INSTALL_ESRGAN = True #@param{type:'boolean'}\n",
        "#@markdown <font size=\"3\">Install Real-ESRGAN Super Resolution</font>\n",
        "INSTALL_KROMO = True #@param{type:'boolean'}\n",
        "#@markdown <font size=\"3\">Install Kromo Chromatic Aberration gnerator</font>\n",
        "INSTALL_MIDAS = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Install timm for MiDaS support (this allows you to export Depth Maps)</font>\n",
        "INSTALL_IMG2TEXTURE = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Install img2texture for tileable seamless texture output.\n",
        "INSTALL_CLIP_INTERROGATOR = True #@param{type: 'boolean'}\n",
        "#@markdown Install CLIP Interrogator by pharmapsychotic\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### <a name=\"otherinstall\">**Other Install Options**</a>\n",
        "CLEAR_SETUP_LOG = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Clear the setup log after installation completes.</font>\n",
        "SUPPRESS_WARNINGS = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Supress warnings from installation scripts and runtime scripts.</font>\n",
        "\n",
        "import os, sys, time, torch, gc, requests, io, shutil, json\n",
        "\n",
        "settings_template = {\n",
        "    'setup': {\n",
        "        'USE_DRIVE_FOR_PICS': False,\n",
        "        'USE_DRIVE_FOR_LOCAL_COPIES': False,\n",
        "        'USE_DRIVE_FOR_MODELS': False,\n",
        "        'INSTALL_GFPGAN': False,\n",
        "        'INSTALL_CODEFORMER': False,\n",
        "        'INSTALL_ESRGAN': False,\n",
        "        'INSTALL_KROMO': False,\n",
        "        'INSTALL_MIDAS': False,\n",
        "        'INSTALL_IMG2TEXTURE': False,\n",
        "        'INSTALL_CLIP_INTERROGATOR': False,\n",
        "        'CLEAR_SETUP_LOG': False,\n",
        "        'SUPPRESS_WARNINGS': True,\n",
        "    },\n",
        "    'prompts': {\n",
        "        'PROMPT': None,\n",
        "        'PROMPT_FILE': None,\n",
        "        'PROMPT_STYLE': None,\n",
        "        'NEW_NSP_ON_ITERATION': True,\n",
        "    },\n",
        "    'inits': {\n",
        "        'INIT_IMAGE': None,\n",
        "        'INIT_MASK': None,\n",
        "        'INIT_SCALE': None,\n",
        "        'RECURSIVE_EVOLUTION': False,\n",
        "    },\n",
        "    'diffusion_settings': {\n",
        "        'MODEL_ID': None,\n",
        "        'SAMPLER': None,\n",
        "        'DDIM_ETA': None,\n",
        "        'STEPS': None,\n",
        "        'SEED': None,\n",
        "        'MAX_SEED': None,\n",
        "        'INCREMENT_ITERATION_SEED': None,\n",
        "        'NUM_ITERS': None,\n",
        "        'WIDTH': None,\n",
        "        'HEIGHT': None,\n",
        "        'SCALE': None,\n",
        "        'PRECISION': None,\n",
        "        'IMAGES_FOLDER': None,\n",
        "        'CACHE_PIPELINES': False,\n",
        "        'RECACHE_PIPES': False,\n",
        "        'SKIP_DIFFUSION_RUN': False,\n",
        "        'ENABLE_NSFW_FILTER': False,\n",
        "        'ENABLE_ATTENTION_SLICES': True,\n",
        "        'LOW_VRAM_PATCH': True,\n",
        "    },\n",
        "    'upscalers': {\n",
        "        'IMAGE_UPSCALER': None,\n",
        "        'UPSCALE_AMOUNT': None,\n",
        "        'ESRGAN_MODE': None,\n",
        "        'CODEFORMER_UPSCALE_AMOUNT': None,\n",
        "        'CODEFORMER_FIDELITY': None,\n",
        "    },\n",
        "    'image_processing': {\n",
        "        'KEEP_ONLY_FINAL_IMAGE': False,\n",
        "        'SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN': True,\n",
        "        'SHARPEN_AMOUNT': None,\n",
        "        'CA_DIFFUSE_IMAGE': False,\n",
        "        'CA_STRENGTH': None,\n",
        "        'CA_JITTER': None,\n",
        "        'CA_OVERLAY': None,\n",
        "        'CA_NO_RADIAL_BLUR': None,\n",
        "        'MEDIAN_FILTER_IMAGE': False,\n",
        "        'MEDIAN_DIAMETER': None,\n",
        "        'MEDIAN_SIGMA_COLOR': None,\n",
        "        'MEDIAN_SIGMA_SPACE': None,\n",
        "        'GENERATE_MIDAS_DEPTH': False,\n",
        "        'SAVE_MIDAS_DEPTH': False,\n",
        "        'MIDAS_TYPE': None,\n",
        "        'MIDAS_MODE': None,\n",
        "        'FDOF_IMAGE': False,\n",
        "        'FDOF_REPLACE_IMAGE': False,\n",
        "        'FDOF_RADIUS': None,\n",
        "        'FDOF_SAMPLES': None,\n",
        "        'TILEABLE_IMAGE': False,\n",
        "        'TILED': True,\n",
        "        'TILE_OVERLAP': None,\n",
        "    },\n",
        "    'clip_interrogator': {\n",
        "        'INTERROGATE_INIT_IAMGE': False,\n",
        "        'INTERROGATE_DIFFUSION_IMAGE': False,\n",
        "        'ViTB32': False,\n",
        "        'ViTB16;': False,\n",
        "        'ViTL14': True,\n",
        "        'ViTL14_336px': True,\n",
        "        'RN101': False,\n",
        "        'RN50': False,\n",
        "        'RN50x4': False,\n",
        "        'RN50x16': False,\n",
        "        'RN50x64': False,\n",
        "        'INTERROGATOR_PROMPT': None,\n",
        "    },\n",
        "    'other_settings': {\n",
        "        'IMAGES_DISPLAY_ABOVE_LOG': False,\n",
        "        'USE_BASIC_IMAGE_DISPLAY': True,\n",
        "        'CLEAR_LOG_BETWEEN_ITERATIONS': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Enable third-party widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# SETUP BASE DIRECTORIES\n",
        "OUTDIR = '/content/Stable_Diffusion/images_out'\n",
        "\n",
        "if USE_DRIVE_FOR_MODELS and USE_DRIVE_FOR_LOCAL_COPIES:\n",
        "    USE_DRIVE_FOR_MODELS = False\n",
        "\n",
        "if USE_DRIVE_FOR_PICS and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "STABLE_DIFFUSION_WORKDIR = '/content/Stable_Diffusion'\n",
        "GDRIVE_WORKDIR = '/content/drive/MyDrive/AI/Stable_Diffusion'\n",
        "\n",
        "if USE_DRIVE_FOR_LOCAL_COPIES:\n",
        "    STABLE_DIFFUSION_WORKDIR = GDRIVE_WORKDIR\n",
        "    if not os.path.exists(STABLE_DIFFUSION_WORKDIR):\n",
        "        os.makedirs(STABLE_DIFFUSION_WORKDIR)\n",
        "if not USE_DRIVE_FOR_LOCAL_COPIES:\n",
        "    if not os.path.exists(STABLE_DIFFUSION_WORKDIR):\n",
        "        os.makedirs(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "sys.path.append(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "drive_model_cache = f'{GDRIVE_WORKDIR}/model_cache'\n",
        "model_cache = f'{STABLE_DIFFUSION_WORKDIR}/model_cache'\n",
        "pipe_cache = f'{STABLE_DIFFUSION_WORKDIR}/cache'\n",
        "\n",
        "moved_from_cache = False\n",
        "last_model = None\n",
        "\n",
        "if not os.path.exists(model_cache):\n",
        "    os.makedirs(model_cache)\n",
        "\n",
        "if not os.path.exists(pipe_cache):\n",
        "    os.makedirs(pipe_cache)\n",
        "\n",
        "# DEFINE NECESSARY FUNCTIONS\n",
        "\n",
        "def packages():\n",
        "    import sys, subprocess\n",
        "    return [r.decode().split('==')[0] for r in subprocess.check_output([sys.executable, '-m', 'pip', 'freeze']).split()]\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    res = subprocess.run(['wget', '-q', '--show-progress', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wgeto(url, outputdir):\n",
        "    res = subprocess.run(['wget', '-q', '--show-progress', url, '-O', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def plotSettings(settingsType=None, locals=None):\n",
        "    global settings\n",
        "    if settingsType and settings.__contains__(settingsType) and type(locals) is dict:\n",
        "        for k in settings[settingsType].keys():\n",
        "            if locals.keys().__contains__(k):\n",
        "                settings[settingsType][k] = locals[k]\n",
        "\n",
        "def fetch_bytes(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        from urllib.request import urlopen \n",
        "        return urlopen(url_or_path) \n",
        "    return open(url_or_path, 'r')\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "def clear():\n",
        "    from IPython.display import clear_output; return clear_output()\n",
        "\n",
        "def time_format(seconds: int):\n",
        "    if seconds is not None:\n",
        "        seconds = int(seconds)\n",
        "        d = seconds // (3600 * 24)\n",
        "        h = seconds // 3600 % 24\n",
        "        m = seconds % 3600 // 60\n",
        "        s = seconds % 3600 % 60\n",
        "        ms = round(seconds * 1000)\n",
        "        if d > 0:\n",
        "            return '{:02d}D {:02d}H {:02d}m {:02d}s'.format(d, h, m, s)\n",
        "        elif h > 0:\n",
        "            return '{:02d}H {:02d}m {:02d}s'.format(h, m, s)\n",
        "        elif m > 0:\n",
        "            return '{:02d}m {:02d}s'.format(m, s)\n",
        "        elif s > 0:\n",
        "            return '{:02d}s'.format(s)\n",
        "        elif ms > 0:\n",
        "            return '{:02d}ms'.format(ms)\n",
        "    return '0s'\n",
        "\n",
        "def text2seed(string, max):\n",
        "    seed = None\n",
        "    def digits(n, max):\n",
        "        import math\n",
        "        ndigits = int(math.log10(n))+1\n",
        "        try:\n",
        "            return n//int(10**(ndigits-max))\n",
        "        except ZeroDivisionError:\n",
        "            return n\n",
        "    if string:\n",
        "        for chr in [*string]:\n",
        "            if seed is None:\n",
        "                seed = str(ord(chr))\n",
        "            else:\n",
        "                seed += str(ord(chr))\n",
        "        seed = digits(int(seed), max)\n",
        "    return seed\n",
        "\n",
        "def gpu_memory_usage(gpu_id):\n",
        "    command = f\"nvidia-smi --id={gpu_id} --query-gpu=memory.used --format=csv\"\n",
        "    output_cmd = subprocess.check_output(command.split())\n",
        "    memory_used = output_cmd.decode(\"ascii\").split(\"\\n\")[1]\n",
        "    memory_used = int(memory_used.split()[0])\n",
        "    return memory_used\n",
        "\n",
        "def gpu_memory_total(gpu_id):\n",
        "    command = f\"nvidia-smi --id={gpu_id} --query-gpu=memory.total --format=csv\"\n",
        "    output_cmd = subprocess.check_output(command.split())\n",
        "    memory_used = output_cmd.decode(\"ascii\").split(\"\\n\")[1]\n",
        "    memory_used = int(memory_used.split()[0])\n",
        "    return memory_used\n",
        "\n",
        "def clean_env(v=False, device=0):\n",
        "    import time\n",
        "    cuda_availabe = torch.cuda.is_available()\n",
        "    mem_used = gpu_memory_usage(device)\n",
        "    mem_total = gpu_memory_total(device)\n",
        "    if v: print(f'VRAM Total: {mem_total}mb, VRAM Allocatd: {mem_used}mb')\n",
        "    stt = int(time.time())\n",
        "    if cuda_availabe:\n",
        "        a = None\n",
        "        try:\n",
        "            a = torch.zeros(sys.maxsize, dtype=torch.int8).cuda()\n",
        "        except Exception:\n",
        "            pass\n",
        "        finally:\n",
        "            del a\n",
        "            torch.cuda.synchronize(); \n",
        "            torch.cuda.empty_cache(); \n",
        "    time.sleep(0.25)\n",
        "    gc.collect()\n",
        "    try:\n",
        "        global midas, transform, prediction, input_batch, depth, depth_image, image, sr_image, enhanced_image, img, init,  original_init\n",
        "        del midas, transform, prediction, input_batch, depth, depth_image, image, sr_image, enhanced_image, img, init,  original_init\n",
        "    except NameError:\n",
        "        pass\n",
        "    time.sleep(1)\n",
        "    if v: print(f':recycling_symbol: Cleared memory.  Time taken was {time_format(int(int(time.time()) - stt))}')\n",
        "    new_mem_used = gpu_memory_usage(device)\n",
        "    if v: print(f'VRAM Allocatd: {new_mem_used}mb, VRAM Released: {mem_used - new_mem_used}mb')\n",
        "    if not cuda_availabe:\n",
        "        print(\":WARNING: There is no CUDA device available! Cannot run diffusion models!\")\n",
        "\n",
        "# Basic image display -- God, what is this monster I've spawned? \n",
        "def displayJsImage(b, i, prepend, name, img):\n",
        "    import cv2\n",
        "    from IPython.display import display, Javascript\n",
        "    from google.colab.output import eval_js\n",
        "    from base64 import b64encode\n",
        "    from google.colab import files\n",
        "    import numpy as np\n",
        "    img = np.asarray(img, dtype=np.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    js = Javascript('''\n",
        "        async function showImage(b, i, prepend, name, image, width, height) {\n",
        "            batchBlock = document.getElementById('batch-block-'+b);\n",
        "            block = document.getElementById('block-'+b+'-'+i)\n",
        "            img = document.getElementById(name);\n",
        "            cont = document.getElementById(name+'_container');\n",
        "\n",
        "            if (batchBlock == null) {\n",
        "                batchBlock = document.createElement('div');\n",
        "                batchBlock.id = 'batch-block-'+b;\n",
        "                batchBlock.style = 'background-color:rgba(0,0,0,0.25);width:auto;margin-bottom:25px;padding:5px;text-align:center;box-shadow: 0px 0px 5px rgba(0,0,0,0.5);';\n",
        "                //batchBlock.innerHTML = '<h2 style=\"background-color:rgba(255,255,255,0.1);margin:0;margin-bottom:5px;padding:4px;text-align:center;text-shadow: 1px 1px rgba(0,0,0,0.35);\">Batch '+b+'</h2>';\n",
        "                if (prepend == 1) {\n",
        "                    document.body.prepend(batchBlock)\n",
        "                } else {\n",
        "                    document.body.appendChild(batchBlock)\n",
        "                }\n",
        "                buttonBt = document.createElement('button');\n",
        "                buttonBt.className = 'collapsible';\n",
        "                buttonBt.style = 'cursor:pointer;width:100%;margin-bottom:5px;border:none;border-bottom:3px solid #999999;padding:5px;text-align:center;font-size:16px;font-weight:bold;color:white;background-color:rgba(155,155,155,0.15);text-shadow: 1px 1px rgba(0,0,0,0.35);transition: all 0.5s;'\n",
        "                buttonBt.innerHTML = 'Batch '+b;\n",
        "                buttonBt.value = 'Batch '+b;\n",
        "                batchBlock.before(buttonBt)\n",
        "            }\n",
        "            if (block == null) {\n",
        "                block = document.createElement('div');\n",
        "                block.id = 'block-'+b+'-'+i;\n",
        "                block.style = 'width: auto;margin-bottom:15px;padding:5px;text-align:center;';\n",
        "                //block.innerHTML = '<h3 style=\"margin:3px;text-align:center;text-shadow: 1px 1px rgba(0,0,0,0.35);\">Iteration '+i+'</h3>';\n",
        "                batchBlock.appendChild(block);\n",
        "                buttonIt = document.createElement('button');\n",
        "                buttonIt.className = 'collapsible';\n",
        "                buttonIt.style = 'cursor:pointer;width:100%;margin-bottom:5px;border:none;border-bottom:3px solid #999999;padding:5px;text-align:center;font-size:16px;font-weight:bold;color:white;background-color:rgba(155,155,155,0.15);text-shadow: 1px 1px rgba(0,0,0,0.35);transition: all 0.5s;'\n",
        "                buttonIt.innerHTML = 'Iteration '+i;\n",
        "                buttonIt.value = 'Iteration '+i;\n",
        "                block.before(buttonIt)\n",
        "            }\n",
        "            if(img == null && cont == null) {\n",
        "                cont = document.createElement('div');\n",
        "                cont.id = name+'_container';\n",
        "                link = document.createElement('a');\n",
        "                link.href = image;\n",
        "                link.target = '_blank';\n",
        "                img = document.createElement('img');\n",
        "                img.id = name;\n",
        "                img.class = \"resultImage\"\n",
        "                cont.style = 'display:inline-block;width:auto;font-size:14px;font-weight:bold;background-color:rgba(0,0,0,0.5);border-radius:5px;padding:2px;margin:2px;box-shadow: 0px 0px 5px rgba(0,0,0,0.5);'\n",
        "                cont.innerHTML = '<p style=\"margin:3px auto;width:180px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-shadow: 1px 1px rgba(0,0,0,0.35);\">'+name+'</p>';\n",
        "                block.appendChild(cont);\n",
        "                cont.appendChild(link);\n",
        "                link.appendChild(img);\n",
        "            }\n",
        "            img.src = image;\n",
        "            img.style = \"margin: 5px; vertical-align: text-top; max-width: 256px; max-height: 512px;\";\n",
        "        }\n",
        "\n",
        "        function debugBase64(base64URL){\n",
        "            var win = window.open();\n",
        "            win.document.write('<iframe src=\"' + base64URL  + '\" frameborder=\"0\" style=\"border:0; top:0px; left:0px; bottom:0px; right:0px; width:100%; height:100%;\" allowfullscreen></iframe>');\n",
        "        }\n",
        "\n",
        "        var coll = document.getElementsByClassName(\"collapsible\");\n",
        "        var i;\n",
        "        for (i = 0; i < coll.length; i++) {\n",
        "\n",
        "            coll[i].addEventListener('mouseover',function(){\n",
        "                this.style.color = 'orange';\n",
        "                this.style.borderBottom = \"3px solid orange\";\n",
        "            })\n",
        "\n",
        "            coll[i].addEventListener('mouseleave',function(){\n",
        "                this.style.color = 'white';\n",
        "                this.style.borderBottom = \"3px solid #999\";\n",
        "            })\n",
        "\n",
        "            coll[i].addEventListener(\"click\", function() {\n",
        "                this.classList.toggle(\"active\");\n",
        "                var content = this.nextElementSibling;\n",
        "                if (content.style.display === \"block\") {\n",
        "                content.style.display = \"none\";\n",
        "                } else {\n",
        "                content.style.display = \"block\";\n",
        "                }\n",
        "            });\n",
        "\n",
        "        }\n",
        "    ''')\n",
        "    height, width = img.shape[:2]\n",
        "    ret, data = cv2.imencode('.png', img)\n",
        "    data = b64encode(data)\n",
        "    data = data.decode()\n",
        "    data = 'data:image/png;base64,' + data\n",
        "    display(js)\n",
        "    eval_js(f'showImage({b}, {i}, {int(prepend)}, \"{name}\", \"{data}\", {width}, {height})')\n",
        "\n",
        "def clearOutputArea(b, i):\n",
        "    from IPython.display import display, Javascript\n",
        "    from google.colab.output import eval_js\n",
        "    js = Javascript('''\n",
        "        function onReady(fn) {\n",
        "            if (document.readyState==='complete' || document.readyState==='interactive') {\n",
        "                setTimeout(fn, 1);\n",
        "            } else {\n",
        "                document.addEventListener(\"DOMContentLoaded\", fn);\n",
        "            }\n",
        "        }\n",
        "        function clearColabOutput(b, i) {\n",
        "            var streams = document.getElementsByClassName('stream');\n",
        "            var dataOutputs = document.getElementsByClassName('display_data');\n",
        "            for(var i = 0; i < streams.length; i++) {\n",
        "                streams[i].innerHTML = '';\n",
        "            }\n",
        "            for(var i = 0; i < dataOutputs.length; i++) {\n",
        "                dataOutputs[i].innerHTML = ''\n",
        "            }\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    eval_js(f'onReady(clearColabOutput({b}, {i}));')\n",
        "\n",
        "def closest_value(input_list, input_value):\n",
        "    difference = lambda input_list : abs(input_list - input_value)\n",
        "    res = min(input_list, key=difference)\n",
        "    return res\n",
        "\n",
        "def printPrompt(prompt, limit=12):\n",
        "    pw = prompt.split(\" \"); i=0; oi=0; pstr = ''\n",
        "    for w in pw:\n",
        "        oi+=1; pstr += f'{w} '\n",
        "        if i is limit or oi is len(pw): print(pstr.strip()); pstr = ''; i = 0; pass\n",
        "        i+=1\n",
        "\n",
        "def sharpenImage(image, samples=1):\n",
        "    import PIL\n",
        "    from PIL import Image, ImageFilter\n",
        "    im = image\n",
        "    for i in range(samples):\n",
        "        im = im.filter(ImageFilter.SHARPEN)\n",
        "    return im\n",
        "\n",
        "def medianFilter(img, diameter, sigmaColor, sigmaSpace):\n",
        "    from PIL import Image\n",
        "    import cv2 as cv\n",
        "    import numpy as np\n",
        "    diameter = int(diameter); sigmaColor = int(sigmaColor); sigmaSpace = int(sigmaSpace)\n",
        "    img = img.convert('RGB')\n",
        "    img = cv.cvtColor(np.array(img), cv.COLOR_RGB2BGR)\n",
        "    img = cv.bilateralFilter(img, diameter, sigmaColor, sigmaSpace)\n",
        "    img = cv.cvtColor(np.array(img), cv.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(img).convert('RGB')\n",
        "\n",
        "def portraitBlur(img, mask, radius=5, samples=1):\n",
        "    from PIL import Image, ImageFilter\n",
        "    mask = mask.resize(img.size).convert('L')\n",
        "    #bimg = img.filter(ImageFilter.BoxBlur(int(boxBlur)))\n",
        "    bimg = medianFilter(img, radius, (radius * 500), 75)\n",
        "    bimg.convert(img.mode)\n",
        "    rimg = None\n",
        "    if samples > 1:\n",
        "        for i in range(samples):\n",
        "            if i is 0:\n",
        "                rimg = Image.composite(img, bimg, mask)\n",
        "            else:\n",
        "                rimg = Image.composite(rimg, bimg, mask)\n",
        "    else:\n",
        "        rimg = Image.composite(img, bimg, mask).convert('RGB')\n",
        "    \n",
        "    return rimg\n",
        "\n",
        "def getInitImages(path, filters='', verbose=False):\n",
        "    ret_images = []\n",
        "    valid = ['.jpeg','.jpg','.gif','.png']\n",
        "    if filters is not '':\n",
        "        filters = [f.strip() for f in filters.split(',')] if ',' in filters else [filters]\n",
        "    if path.startswith('http://') or path.startswith('https://'):\n",
        "        add = True\n",
        "        if filters is not '':\n",
        "            add = False\n",
        "            for f in filters:\n",
        "                if f in os.path.basename(path):\n",
        "                    add = True\n",
        "        if add:\n",
        "            if verbose: print(f'Found 1 remote image: {path}\\n')\n",
        "            return path\n",
        "        else: \n",
        "            if verbose: print(f'Found no valid image(s)\\n')\n",
        "            return None\n",
        "    if os.path.isdir(path):\n",
        "        try:\n",
        "            images = next(os.walk(path), (None, None, []))[2]\n",
        "            ret_images = []\n",
        "            if images:\n",
        "                if verbose: print(f\"Found {len(images)} image(s) in {path}\\n\")\n",
        "                for img in images:\n",
        "                    ext = os.path.splitext(img)[1]\n",
        "                    if ext in valid:\n",
        "                        add = True\n",
        "                        if filters is not '':\n",
        "                            add = False\n",
        "                            if verbose: print(\"Filtering with:\", filters)\n",
        "                            for f in filters:\n",
        "                                if f in img:\n",
        "                                    add = True\n",
        "                        if add:\n",
        "                            img = f'{path}/{img}'\n",
        "                            if verbose: print(f' -> {img}', defaultprint=True)\n",
        "                            ret_images.append(img)\n",
        "                print('')\n",
        "            if len(ret_images) == 0:\n",
        "                if verbose: print(f'Found no valid image(s)\\n')\n",
        "                return None\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "    elif os.path.isfile(path):\n",
        "        try:\n",
        "            if path.lower().endswith('.txt'):\n",
        "                with open(path, \"r\") as f:\n",
        "                    images = f.read().splitlines()\n",
        "                    if images:\n",
        "                        ret_images = []\n",
        "                        if verbose: print(f\"Found {len(images)} image(s) in {path}\\n\")\n",
        "                        for img in images:\n",
        "                            ext = os.path.splitext(img)[1]\n",
        "                            if ext in valid:\n",
        "                                add = True\n",
        "                                if verbose: print(\"Filtering with:\", filters)\n",
        "                                if filters is not '':\n",
        "                                    add = False\n",
        "                                    for f in filters:\n",
        "                                        if f in img:\n",
        "                                            add = True\n",
        "                                if add:\n",
        "                                    if verbose: print(f' -> {img}', defaultprint=True)\n",
        "                                    ret_images.append(img)\n",
        "                        print('')\n",
        "            else:\n",
        "                ext = os.path.splitext(path)[1]\n",
        "                if ext.lower() in valid:\n",
        "                    add = True\n",
        "                    if filters is not '':\n",
        "                        add = False\n",
        "                        for f in filters:\n",
        "                            if f in os.path.basename(path):\n",
        "                                add = True\n",
        "                    if add:\n",
        "                        if verbose: print(f'Found 1 image: {path}\\n')\n",
        "                        return path\n",
        "                    else:\n",
        "                        if verbose: print(f'Found no valid image(s)\\n')\n",
        "                        return None\n",
        "                else:\n",
        "                    if verbose: print(f'Found no valid image(s)\\n')\n",
        "                    return None\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "    return ret_images\n",
        "\n",
        "def setup_pipes(pipe_type='default', model_id=None, model_cache=None,):\n",
        "    from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "    if pipe_type is 'lowvram':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up half-float pipeline...\")\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "        del pipe.vae.encoder\n",
        "    elif pipe_type is 'img2img':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up image-to-image pipeline...\")\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "    elif pipe_type is 'inpaint':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up inpainting image-to-image pipeline...\")\n",
        "        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\")\n",
        "    elif pipe_type is 'default':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up default full-float text-to-image pipeline...\")\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, use_auth_token=True).to(\"cuda\")\n",
        "    return pipe\n",
        "\n",
        "def cache_pipes(pipe_type, model_id, model_cache, pipe_cache):\n",
        "    global RECACHE_PIPES\n",
        "    import joblib, os, gc\n",
        "    from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "    \n",
        "    if pipe_type is 'lowvram':\n",
        "        if not os.path.exists(f'{pipe_cache}/LOW_VRAM_PIPE.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\"), f'{pipe_cache}/LOW_VRAM_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/LOW_VRAM_PIPE.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/LOW_VRAM_PIPE.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/LOW_VRAM_PIPE.obj')\n",
        "        del pipe.vae.encoder\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    if pipe_type is 'img2img':\n",
        "        if not os.path.exists(f'{pipe_cache}/IMG2IMG_PIPE.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionImg2ImgPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\"), f'{pipe_cache}/IMG2IMG_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/IMG2IMG_PIPE.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/IMG2IMG_PIPE.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/IMG2IMG_PIPE.obj')\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    if pipe_type is 'inpaint':\n",
        "        if not os.path.exists(f'{pipe_cache}/INPAINT_PIPE.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionInpaintPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(\"cuda\"), f'{pipe_cache}/INPAINT_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/INPAINT_PIPE.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/INPAINT_PIPE.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/INPAINT_PIPE.obj')\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    if pipe_type is 'default':\n",
        "        if not os.path.exists(f'{pipe_cache}/DEFAULT.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, use_auth_token=True).to(\"cuda\"), f'{pipe_cache}/DEFAULT_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/DEFAULT.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/DEFAULT.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/DEFAULT_PIPE.obj')\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    return None\n",
        "\n",
        "def safetyCheckerDummy(images, **kwargs):\n",
        "    return images, False\n",
        "\n",
        "def preprocess(image):\n",
        "    import PIL\n",
        "    import numpy as np\n",
        "    w, h = image.size\n",
        "    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "    image = np.array(image).astype(np.float32) / 255.0\n",
        "    image = image[None].transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    return 2.0 * image - 1.0\n",
        "\n",
        "# Optimization Functions\n",
        "\n",
        "def forward(self, x, context=None, mask=None):\n",
        "\n",
        "    import math\n",
        "    from torch import einsum\n",
        "    import subprocess\n",
        "    try:\n",
        "      from einops import rearrange\n",
        "    except ModuleNotFoundError:\n",
        "      subprocess.run(['pip', 'install', 'einops'], stdout=subprocess.DEVNULL)\n",
        "      from einops import rearrange\n",
        "    import types\n",
        "    from diffusers.models.attention import CrossAttention\n",
        "    import torch\n",
        "    batch_size, sequence_length, dim = x.shape\n",
        "\n",
        "    h = self.heads\n",
        "\n",
        "    q = self.to_q(x)\n",
        "    context = context if context is not None else x\n",
        "    k = self.to_k(context)\n",
        "    v = self.to_v(context)\n",
        "    del context, x\n",
        "\n",
        "    q = self.reshape_heads_to_batch_dim(q)\n",
        "    k = self.reshape_heads_to_batch_dim(k)\n",
        "    v = self.reshape_heads_to_batch_dim(v)\n",
        "\n",
        "    r1 = torch.zeros(q.shape[0], q.shape[1], v.shape[2], device=q.device)\n",
        "\n",
        "    stats = torch.cuda.memory_stats(q.device)\n",
        "    mem_total = torch.cuda.get_device_properties(0).total_memory\n",
        "    mem_active = stats['active_bytes.all.current']\n",
        "    mem_free = mem_total - mem_active\n",
        "\n",
        "    mem_required = q.shape[0] * q.shape[1] * k.shape[1] * 4 * 2.5\n",
        "    steps = 1\n",
        "\n",
        "    if mem_required > mem_free:\n",
        "        steps = 2**(math.ceil(math.log(mem_required / mem_free, 2)))\n",
        "\n",
        "    slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n",
        "    for i in range(0, q.shape[1], slice_size):\n",
        "        end = i + slice_size\n",
        "        s1 = einsum('b i d, b j d -> b i j', q[:, i:end], k)\n",
        "        s1 *= self.scale\n",
        "\n",
        "        s2 = s1.softmax(dim=-1)\n",
        "        del s1\n",
        "\n",
        "        r1[:, i:end] = einsum('b i j, b j d -> b i d', s2, v)\n",
        "        del s2\n",
        "\n",
        "    del q, k, v\n",
        "\n",
        "    r2 = rearrange(r1, '(b h) n d -> b n (h d)', h=h)\n",
        "    del r1\n",
        "\n",
        "    return self.to_out(r2)\n",
        "\n",
        "def optimize_attention(model):\n",
        "    import types\n",
        "    from diffusers.models.attention import CrossAttention\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, CrossAttention):\n",
        "            module.forward = types.MethodType(forward, module)\n",
        "\n",
        "# End Optimization Functions\n",
        "\n",
        "def move_files(source, destination):\n",
        "    for src_dir, dirs, files in os.walk(source):\n",
        "        dst_dir = src_dir.replace(source, destination)\n",
        "        if not os.path.exists(dst_dir):\n",
        "            os.mkdir(dst_dir)\n",
        "        for file_ in files:\n",
        "            src_file = os.path.join(src_dir, file_)\n",
        "            dst_file = os.path.join(dst_dir, file_)\n",
        "            if os.path.exists(dst_file):\n",
        "                os.remove(dst_file)\n",
        "            shutil.copy(src_file, dst_dir)\n",
        "\n",
        "def download_model(model_id, redownload=False):\n",
        "    import os, shutil\n",
        "    global moved_from_cache, last_model\n",
        "    rep = ['CompVis/','hakurei/']\n",
        "    localf = model_id\n",
        "    for r in rep:\n",
        "        localf = model_id.replace(r, '')\n",
        "    model = f'{model_cache}/{localf}'\n",
        "    if redownload and moved_from_cache:\n",
        "        moved_from_cache = False\n",
        "    drive_model = f'{drive_model_cache}/{localf}'\n",
        "    if USE_DRIVE_FOR_MODELS and not USE_DRIVE_FOR_LOCAL_COPIES and not moved_from_cache and not redownload:\n",
        "        print(\":open_file_folder: Moving model files to model cache from drive cache ...\")\n",
        "        if not os.path.exists(model_cache):\n",
        "            os.makedirs(model_cache)\n",
        "        if os.path.exists(drive_model) or len(os.listdir(drive_model_cache)) > 0:\n",
        "            try:\n",
        "                move_files(drive_model_cache, model_cache)\n",
        "                print(\":check_mark_button: Move complete.\")\n",
        "                redownload = False\n",
        "                moved_from_cache = True\n",
        "            except OSError as e:\n",
        "                redownload = True\n",
        "                print(\"Uneable to move model cache from:\", drive_model_cache)\n",
        "                pass\n",
        "        else:\n",
        "            print(f':WARNING: \\'{model_id}\\' doesn\\'t exist in \\'{drive_model_cache}\\', or any other model weights or models!')\n",
        "            redownload = True\n",
        "    if redownload:\n",
        "        if os.path.exists(model):\n",
        "            shutil.rmtree(model)\n",
        "        os.chdir(model_cache)\n",
        "        print(\":hourglass_not_done: Downloading model weights for:\", model_id)\n",
        "        print(subprocess.run(['git', 'clone', f'https://{hu}:{ht}@huggingface.co/{model_id}'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(\":check_mark_button: Downloaded complete.\")\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "    if USE_DRIVE_FOR_MODELS and not USE_DRIVE_FOR_LOCAL_COPIES and not moved_from_cache:\n",
        "        print(\":open_file_folder: Moving model files to drive cache ...\")\n",
        "        if not os.path.exists(drive_model_cache):\n",
        "            os.makedirs(drive_model_cache)\n",
        "        if os.path.exists(model) or len(os.listdir(model_cache)) > 0:\n",
        "            move_files(model_cache, drive_model_cache)\n",
        "            print(\":check_mark_button: Move complete.\")\n",
        "        else:\n",
        "            print(f':WARNING: \\'{model_id}\\' doesn\\'t exist in \\'{model_cache}\\', or any other model weights or models!')\n",
        "        moved_from_cache = True\n",
        "\n",
        "# End Optimization Functions\n",
        "\n",
        "# SETUP DEPENDENCIES\n",
        "print(\"\\nStarting Installation Processess.\\nThis should take approximately one eternity...\\n\")\n",
        "\n",
        "try:\n",
        "  with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "    k = f.read().decode('utf-8').split(':'); hu = k[0].strip(); ht = k[1].strip()\n",
        "except OSError as e:\n",
        "  raise e\n",
        "\n",
        "try:\n",
        "\n",
        "    # Install psutil\n",
        "    if 'psutil' in packages():\n",
        "        print(':check_mark_button: \\'psutil\\' installed.\\n')\n",
        "    else:\n",
        "        print(':hourglass_not_done: Installing \\'psutil\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', 'psutil'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'psutil\\' installed.\\n')\n",
        "    import psutil\n",
        "\n",
        "    if 'joblib' in packages():\n",
        "        print(':check_mark_button: \\'joblib\\' installed.\\n')\n",
        "    else:\n",
        "        print(':hourglass_not_done: Installing \\'joblib\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', 'joblib'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'joblib\\' installed.\\n')\n",
        "    import joblib\n",
        "    from joblib import Memory\n",
        "    cache_dir = f'{STABLE_DIFFUSION_WORKDIR}/cache'\n",
        "\n",
        "    # Install Shutup\n",
        "    if 'shutup' not in packages():\n",
        "        subprocess.run(['pip', '-q', 'install', 'shutup'], stdout=subprocess.DEVNULL)\n",
        "    import shutup; \n",
        "    if SUPPRESS_WARNINGS: \n",
        "        shutup.please()\n",
        "\n",
        "    import warnings\n",
        "    if SUPPRESS_WARNINGS:\n",
        "        warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
        "    \n",
        "    #rint(subprocess.run(['git', 'lfs', 'install'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    #os.environ['GIT_LFS_SKIP_SMUDGE'] = \"0\"\n",
        "\n",
        "    # This will take a while\n",
        "\n",
        "    # Install Diffusers\n",
        "    if 'diffusers' not in packages():\n",
        "        print(':hourglass_not_done: Installing \\'diffusers\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', '-U', 'git+https://github.com/huggingface/diffusers.git'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'diffusers\\' installed.\\n')\n",
        "\n",
        "    # Patch Safety Checker\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/safety_checker.py', 'safety_checker.py')\n",
        "        shutil.copy('safety_checker.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    # Patch Stable Diffusion Pipelines\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py', 'pipeline_stable_diffusion.py')\n",
        "        shutil.copy('pipeline_stable_diffusion.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py', 'pipeline_stable_diffusion_img2img.py')\n",
        "        shutil.copy('pipeline_stable_diffusion_img2img.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py', 'pipeline_stable_diffusion_inpaint.py')\n",
        "        shutil.copy('pipeline_stable_diffusion_inpaint.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    if 'transformers' not in packages():\n",
        "        print(':hourglass_not_done: Installing \\'transformers\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', 'transformers'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'transformers\\' installed.\\n')\n",
        "\n",
        "    print(':hourglass_not_done: Installing pytorch dependencies...')\n",
        "    res = ''\n",
        "    if 'pytorch-pretrained-bert' not in packages():\n",
        "        res += subprocess.run(['pip', '-q', 'install', 'pytorch-pretrained-bert'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    if 'spacy' not in packages():\n",
        "        res += subprocess.run(['pip', '-q', 'install', 'spacy'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    if 'ftfy' not in packages():\n",
        "        res += subprocess.run(['pip', '-q', 'install', 'ftfy'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "    print(':check_mark_button: pytorch dependencies installed.\\n')\n",
        "\n",
        "    if 'spacy' not in packages():\n",
        "        print(':hourglass_not_done: Setting up \\'spacy\\' ...\\n')\n",
        "        if SUPPRESS_WARNINGS:\n",
        "            subprocess.run(['python', '-m', 'spacy', 'download', 'en'], stdout=subprocess.DEVNULL)\n",
        "        else:\n",
        "            print(subprocess.run(['python', '-m', 'spacy', 'download', 'en'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'spacy\\' setup complete.\\n')\n",
        "    else:\n",
        "        print(':check_mark_button: \\'spacy\\' installed.\\n')\n",
        "\n",
        "    if 'scipy' not in packages():\n",
        "        print(':hourglass_not_done: Installing \\'scipy\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', 'scipy'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    print(':check_mark_button: \\'scipy\\' installed.\\n')\n",
        "\n",
        "    if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/k-diffusion'):\n",
        "        print(':hourglass_not_done: Installing \\'k-diffusers\\' ...')\n",
        "        print(subprocess.run(['git', 'clone', '--quiet', '--recursive', 'https://github.com/crowsonkb/k-diffusion.git'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    else:\n",
        "        print(':check_mark_button: \\'k-diffusion\\' installed.\\n')\n",
        "\n",
        "    print(':globe_with_meridians: Logging into HuggingFace API...')\n",
        "    subprocess.run(['git', 'config', '--global', 'credential.helper', 'store'], stdout=subprocess.DEVNULL)\n",
        "    left_of_pipe = subprocess.Popen([\"echo\", ht], stdout=subprocess.PIPE)\n",
        "    right_of_pipe = subprocess.run(['huggingface-cli', 'login'], stdin=left_of_pipe.stdout, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(right_of_pipe)\n",
        "\n",
        "    if INSTALL_GFPGAN:\n",
        "        print(\"\\n:hourglass_not_done: Installing GFPGAN...\")\n",
        "        res = ''\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/GFPGAN'):\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/TencentARC/GFPGAN.git'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/GFPGAN')\n",
        "            wget(\"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\", \"experiments/pretrained_models\")\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            \n",
        "        if ['basicsr', 'facexlib'] not in packages():\n",
        "            res += subprocess.run(['pip', '-q', 'install', 'basicsr', 'facexlib'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            res += subprocess.run(['pip', '-q', 'install', '-r', 'requirements.txt'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if SUPPRESS_WARNINGS:\n",
        "                subprocess.run(['python', 'setup.py', 'develop'], stdout=subprocess.DEVNULL)\n",
        "            else:\n",
        "                res += subprocess.run(['python', 'setup.py', 'develop'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if 'realesrgan' not in packages():\n",
        "            res += subprocess.run(['pip', '-q', 'install', 'realesrgan'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        print(res)\n",
        "        print(\":check_mark_button: GFPGAN installed!\\n\")\n",
        "        \n",
        "    if INSTALL_ESRGAN:\n",
        "        print(\"\\n:hourglass_not_done: Installing Real-ESRGAN\")\n",
        "        res = ''\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN'):\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/sberbank-ai/Real-ESRGAN'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            res += subprocess.run(['pip', '-q', 'install', '-r', 'Real-ESRGAN/requirements.txt'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            wget(\"https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x2.pth\", \"Real-ESRGAN/weights/\")\n",
        "            wget(\"https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x4.pth\", \"Real-ESRGAN/weights/\")\n",
        "            wget(\"https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x8.pth\", \"Real-ESRGAN/weights/\")\n",
        "        print(res)\n",
        "        print(\":check_mark_button: Real-ESRGAN installed!\\n\")\n",
        "        \n",
        "        def upscale(image, scale, device='cuda'):\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN')\n",
        "            from realesrgan import RealESRGAN\n",
        "            device = torch.device(device)\n",
        "            model = RealESRGAN(device, scale = scale)\n",
        "            model.load_weights(f'weights/RealESRGAN_x{scale}.pth')\n",
        "            sr_image = model.predict(np.array(image))\n",
        "            del model, device\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}')\n",
        "            return sr_image\n",
        "\n",
        "    if INSTALL_CODEFORMER:\n",
        "        print(\":hourglass_not_done: Installing CodeFormer...\\n\")\n",
        "        res = ''\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer'):\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/sczhou/CodeFormer.git'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "        os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer')\n",
        "        if ['codeformer','CodeFormer'] not in packages():\n",
        "            res += subprocess.run(['pip', '-q', 'install', '-r', 'requirements.txt'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            # Install basicsr\n",
        "            if SUPPRESS_WARNINGS:\n",
        "                subprocess.run(['python', 'basicsr/setup.py', 'develop'], stdout=subprocess.DEVNULL)\n",
        "            else:\n",
        "                res += subprocess.run(['python', 'basicsr/setup.py', 'develop'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "            # Download the pre-trained model\n",
        "            if SUPPRESS_WARNINGS:\n",
        "                subprocess.run(['python', 'scripts/download_pretrained_models.py', 'facelib'], stdout=subprocess.DEVNULL)\n",
        "                subprocess.run(['python', 'scripts/download_pretrained_models.py', 'CodeFormer'], stdout=subprocess.DEVNULL)\n",
        "            else: \n",
        "                res += subprocess.run(['python', 'scripts/download_pretrained_models.py', 'facelib'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                res += subprocess.run(['python', 'scripts/download_pretrained_models.py', 'CodeFormer'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(res)\n",
        "            os.makedirs('temp', exist_ok=True)\n",
        "            os.makedirs('results', exist_ok=True)\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        print(\":check_mark_button: CodeFormer installed!\\n\")\n",
        "\n",
        "    if INSTALL_KROMO:\n",
        "        if 'kromo' not in packages():\n",
        "            print(\":hourglass_not_done: Installing \\'kromo\\' ...\")\n",
        "            res = ''\n",
        "            if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/kromo'):\n",
        "                os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "                res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/yoonsikp/kromo'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if 'kromo' not in packages():\n",
        "                os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/kromo')\n",
        "                res += subprocess.run(['pip', '-q', 'install', '-r', 'requirements.txt'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        print(res)\n",
        "        print(':check_mark_button: \\'kromo\\' installed.\\n')\n",
        "\n",
        "    if INSTALL_MIDAS:\n",
        "        if 'timm' not in packages():\n",
        "            print(\":hourglass_not_done: Installing MiDaS compatibility...\")\n",
        "            print(subprocess.run(['pip', '-q', 'install', 'timm'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(\":check_mark_button: MiDaS compatibility installed!\\n\")\n",
        "\n",
        "    if INSTALL_IMG2TEXTURE:\n",
        "        if 'img2texture' not in packages():\n",
        "            print(\":hourglass_not_done: Installing \\'img2texture\\' ...\")\n",
        "            print(subprocess.run(['pip3', '-q', 'install', 'img2texture'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(\":check_mark_button: img2texture installed.\\n\")\n",
        "\n",
        "    # Colab Param Scraper\n",
        "    try:\n",
        "        from colabparamscraper.paramscraper import paramScraper\n",
        "    except ImportError:\n",
        "        print(\":hourglass_not_done: Installing Colab paramScraper ...\")\n",
        "        print(subprocess.run(['git', 'clone', '--quiet', 'https://github.com/WASasquatch/colabparamscraper'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    finally:\n",
        "        from colabparamscraper.paramscraper import paramScraper\n",
        "        print(\":check_mark_button: Colab paramScraper installed!\\n\")\n",
        "    \n",
        "    # Noodle Soup prompts\n",
        "    try:\n",
        "        import nsp_pantry\n",
        "    except ImportError:\n",
        "        if not os.path.exists('nsp_pantry.py'):\n",
        "            print(\":hourglass_not_done: Installing Noodle Soup Prompts...\")\n",
        "            wget('https://raw.githubusercontent.com/WASasquatch/noodle-soup-prompts/main/nsp_pantry.py', './')\n",
        "    finally:\n",
        "        import nsp_pantry\n",
        "        from nsp_pantry import nsp_parse\n",
        "\n",
        "    if nsp_parse:\n",
        "        print(\"\\r\\r:check_mark_button: \\33[32mNSP installed successfuly.\\33[0m \\x1B[3mMmm... Noodle Soup.\\x1B[0m\\n\")\n",
        "\n",
        "    # CLIP Interrogator\n",
        "    if INSTALL_CLIP_INTERROGATOR:\n",
        "\n",
        "        res = ''\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        print(\":hourglass_not_done: Installing CLIP Interrogator, and dependencies ...\")\n",
        "        if ['regex', 'tqdm', 'transformers', 'time', 'fairscale'] not in packages():\n",
        "            res += subprocess.run(['pip', '-q', 'install', 'regex', 'tqdm', 'transformers', 'timm', 'fairscale==0.4.4'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if 'clip' not in packages():\n",
        "            res += subprocess.run(['pip', '-q', 'install', 'git+https://github.com/openai/CLIP.git'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/clip-interrogator'):\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/pharmapsychotic/clip-interrogator.git'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/BLIP'):\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/salesforce/BLIP'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        print(res)\n",
        "\n",
        "        sys.path.append(f'{STABLE_DIFFUSION_WORKDIR}/BLIP')\n",
        "        interrogator_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        interrogator_device = 'cpu'\n",
        "\n",
        "        import clip\n",
        "        import pandas as pd\n",
        "        import requests\n",
        "        import torch\n",
        "        import torchvision.transforms as T\n",
        "        import torchvision.transforms.functional as TF\n",
        "\n",
        "        from IPython.display import display\n",
        "        from PIL import Image\n",
        "        from torch import nn\n",
        "        from torch.nn import functional as F\n",
        "        from torchvision import transforms\n",
        "        from torchvision.transforms.functional import InterpolationMode\n",
        "            \n",
        "        from BLIP.models.blip import blip_decoder\n",
        "        \n",
        "        #%cd /content/BLIP\n",
        "\n",
        "        os.environ['TF_FP16_MATMUL_USE_FP32_COMPUTE']='1'\n",
        "        #os.environ['TF_FP16_MATMUL_USE_FP32_COMPUTE=1']='1'\n",
        "\n",
        "        def generate_caption(pil_image):\n",
        "            gpu_image = transforms.Compose([\n",
        "                transforms.Resize((blip_image_eval_size, blip_image_eval_size), interpolation=InterpolationMode.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "            ])(pil_image).unsqueeze(0).to(interrogator_device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                caption = blip_model.generate(gpu_image, sample=False, num_beams=3, max_length=20, min_length=5)\n",
        "            del gpu_image\n",
        "            return caption[0]\n",
        "\n",
        "        def load_list(filename):\n",
        "            with open(filename, 'r', encoding='utf-8', errors='replace') as f:\n",
        "                items = [line.strip() for line in f.readlines()]\n",
        "            return items\n",
        "\n",
        "        def rank(model, image_features, text_array, top_count=1):\n",
        "            top_count = min(top_count, len(text_array))\n",
        "            text_tokens = clip.tokenize([text for text in text_array]).to(interrogator_device)\n",
        "            with torch.no_grad():\n",
        "                text_features = model.encode_text(text_tokens).float()\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            similarity = torch.zeros((1, len(text_array))).to(interrogator_device)\n",
        "            for i in range(image_features.shape[0]):\n",
        "                similarity += (100.0 * image_features[i].unsqueeze(0) @ text_features.T).softmax(dim=-1)\n",
        "            similarity /= image_features.shape[0]\n",
        "\n",
        "            top_probs, top_labels = similarity.cpu().topk(top_count, dim=-1)  \n",
        "            \n",
        "            del similarity\n",
        "\n",
        "            return [(text_array[top_labels[0][i].numpy()], (top_probs[0][i].numpy()*100)) for i in range(top_count)]\n",
        "\n",
        "        def interrogate(image, models):\n",
        "\n",
        "            from  torch.cuda.amp import autocast\n",
        "\n",
        "            caption = generate_caption(image)\n",
        "            if len(models) == 0:\n",
        "                print(f\"\\n\\n{caption}\")\n",
        "                return\n",
        "\n",
        "            table = []\n",
        "            bests = [[('',0)]]*5\n",
        "\n",
        "            print('\\n\\033[1mCLIP Interrogator:\\033[0m\\n')\n",
        "\n",
        "            with autocast():\n",
        "\n",
        "                for model_name in models:\n",
        "                    print(f\":magnifying_glass_tilted_right: Interrogating with {model_name}...\")\n",
        "                    model, preprocess = clip.load(model_name)\n",
        "                    model.to(interrogator_device).eval()\n",
        "\n",
        "                    images = preprocess(image).unsqueeze(0).to(interrogator_device)\n",
        "                    with torch.no_grad():\n",
        "                        image_features = model.encode_image(images).float32()\n",
        "                    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                    ranks = [\n",
        "                        rank(model, image_features, mediums),\n",
        "                        rank(model, image_features, [\"by \"+artist for artist in artists]),\n",
        "                        rank(model, image_features, trending_list),\n",
        "                        rank(model, image_features, movements),\n",
        "                        rank(model, image_features, flavors, top_count=3)\n",
        "                    ]\n",
        "\n",
        "                    for i in range(len(ranks)):\n",
        "                        confidence_sum = 0\n",
        "                        for ci in range(len(ranks[i])):\n",
        "                            confidence_sum += ranks[i][ci][1]\n",
        "                        if confidence_sum > sum(bests[i][t][1] for t in range(len(bests[i]))):\n",
        "                            bests[i] = ranks[i]\n",
        "\n",
        "                    row = [model_name]\n",
        "                    for r in ranks:\n",
        "                        row.append(', '.join([f\"{x[0]} ({x[1]:0.1f}%)\" for x in r]))\n",
        "\n",
        "                    table.append(row)\n",
        "\n",
        "                    clean_env()\n",
        "\n",
        "            display(pd.DataFrame(table, columns=[\"Model\", \"Medium\", \"Artist\", \"Trending\", \"Movement\", \"Flavors\"]))\n",
        "\n",
        "            flaves = ', '.join([f\"{x[0]}\" for x in bests[4]])\n",
        "            medium = bests[0][0][0]\n",
        "            interrogator_prompt = ''\n",
        "            if caption.startswith(medium):\n",
        "                interrogator_prompt = f\"{caption} {bests[1][0][0]}, {bests[2][0][0]}, {bests[3][0][0]}, {flaves}\"\n",
        "            else:\n",
        "                interrogator_prompt = f\"{caption}, {medium} {bests[1][0][0]}, {bests[2][0][0]}, {bests[3][0][0]}, {flaves}\"\n",
        "\n",
        "            globals().update({'INTERROGATOR_PROMPT': interrogator_prompt})\n",
        "\n",
        "            print('\\033[0m:black_nib: Prompt:')\n",
        "            print(f'{interrogator_prompt}\\033[1m\\n\\n')\n",
        "\n",
        "            del table, image_features, model, preprocess\n",
        "            clean_env()\n",
        "\n",
        "        def do_interrogate(image, show_thumb=False):\n",
        "\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/BLIP')\n",
        "\n",
        "            blip_image_eval_size = 384\n",
        "            blip_model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model*_base_caption.pth'        \n",
        "            blip_model = blip_decoder(pretrained=blip_model_url, image_size=blip_image_eval_size, vit='base')\n",
        "            blip_model.eval()\n",
        "            blip_model = blip_model.to(interrogator_device)\n",
        "\n",
        "            globals().update({'blip_model': blip_model, 'blip_image_eval_size': blip_image_eval_size})\n",
        "\n",
        "            models = []\n",
        "            if ViTB32: models.append('ViT-B/32')\n",
        "            if ViTB16: models.append('ViT-B/16')\n",
        "            if ViTL14: models.append('ViT-L/14')\n",
        "            if ViTL14_336px: models.append('ViT-L/14@336px')\n",
        "            if RN101: models.append('RN101')\n",
        "            if RN50: models.append('RN50')\n",
        "            if RN50x4: models.append('RN50x4')\n",
        "            if RN50x16: models.append('RN50x16')\n",
        "            if RN50x64: models.append('RN50x64')\n",
        "\n",
        "            if show_thumb:\n",
        "                thumb = image.copy()\n",
        "                thumb.thumbnail([blip_image_eval_size, blip_image_eval_size])\n",
        "                display(thumb)\n",
        "                thumb.close()\n",
        "                del thumb\n",
        "\n",
        "            interrogate(image, models=models)\n",
        "\n",
        "            del blip_model\n",
        "            clean_env()\n",
        "\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "        data_path = f\"{STABLE_DIFFUSION_WORKDIR}/clip-interrogator/data/\"\n",
        "\n",
        "        artists = load_list(os.path.join(data_path, 'artists.txt'))\n",
        "        flavors = load_list(os.path.join(data_path, 'flavors.txt'))\n",
        "        mediums = load_list(os.path.join(data_path, 'mediums.txt'))\n",
        "        movements = load_list(os.path.join(data_path, 'movements.txt'))\n",
        "\n",
        "        sites = ['Artstation', 'behance', 'cg society', 'cgsociety', 'deviantart', 'dribble', 'flickr', 'instagram', 'pexels', 'pinterest', 'pixabay', 'pixiv', 'polycount', 'reddit', 'shutterstock', 'tumblr', 'unsplash', 'zbrush central']\n",
        "        trending_list = [site for site in sites]\n",
        "        trending_list.extend([\"trending on \"+site for site in sites])\n",
        "        trending_list.extend([\"featured on \"+site for site in sites])\n",
        "        trending_list.extend([site+\" contest winner\" for site in sites])\n",
        "\n",
        "        print(\":check_mark_button: CLIP Interrogator Installed!\")\n",
        "\n",
        "except OSError as e:\n",
        "    raise e\n",
        "except BaseException as e:\n",
        "    raise e\n",
        "finally:\n",
        "    if CLEAR_SETUP_LOG: clear()\n",
        "    print(f\"\\n--[ :confetti_ball::party_popper: \\033[1m\\33[32mEasy Diffusion Environment Setup Complete\\33[0m :party_popper::confetti_ball: ]--\")\n",
        "\n",
        "from PIL import Image, ImageFilter\n",
        "from io import BytesIO\n",
        "import random, pprint, requests\n",
        "from contextlib import contextmanager, nullcontext\n",
        "from torch import autocast\n",
        "from diffusers import PNDMScheduler, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "\n",
        " # Styles\n",
        "style = {\n",
        "\t\"Anime (Japanese Animation Inspired)\": \"Kodomo Style, MOE Anime Style, Ecchi, highly detailed, shadows and highlights, Vibrant Color Scheme, trending on ArtStation, Pixiv --Watermark\",\n",
        "\t\"Cartoon (Matt Groening)\": \"Cartoon, American Animation, The Simpsons Art Style, in the Style of Matt Groening and Chris (Simpsons artist), Flat Colors, Lined Cartoon Art, High Resolution, High Quality, Gracie Films --Watermark, border, frame, image compression\",\n",
        "    \"Cartoon (Seth McFarlane)\": \"Cartoon, American Animation, Family Guy ARt Style, in the Style of Seth MacFarlane and Butch Hartman, Flat Colors, Lined Cartoon Art, High Resolution, High Quality, Underdog Productions Animation, Fuzzy Door Productions Animation --Watermark, border, frame, image compression\",\n",
        "    \"Cosmic (Space Art Style)\": \"Science Fiction, Scifi Theme, Cyberpunk, Outer Space, Deep Space, Cosmic Style, Starfield, Nebulas and distant galeies, Astro, Digital Illustration, In the Style of Gabriel Björk Stiernström and John Berkey --Watermark, image compression, film grain, noise\",\n",
        "    \"Cyberpunk\": \"Cyberpunk, Outer Space, Hyper Realistic, ArtStation, CGSociety, Neon lights, Cinematic Lighting, Volumetric Lighting, Realistic Surrealism, Style of Thomas Kinkade and Soufiane Idrassi --Watermark\",\n",
        "\t\"Dragan (Andrzej Dragan Inspired)\": \"photorealistic color scheme, digital photography, dragan effect, dragan style, high contrast detail, dirty, gritty, urban, color photo --Watermark\",\n",
        "\t\"Dystopian (Bleak)\": \"Photorealistic, Highly Detailed Illustration, Beautiful Aesthetic, Digitial Painting, Dystopian, Moody Atmosphere, Bleak Looking, Eartly, Terrestrial Society, Natural Color Scheme, Hopeless World, Earthborn, Salvaged Materials, Recycled World, Volumetric Lighting, Cinematic, by Ilya Kuvshinov and Aaron Jasinski --Watermark, Border, Frame, Noise, Bloody Skin\",\n",
        "    \"Exopunk (Extreterrestrial Cyberpunk Inspired)\": \"Extraterrestrial Exopunk, Psychedelic Zaha Hadid, Outer Space, Exoplanet, Alien Technology, Colored Lights, Volumetric Lighting, Cinematic Lighting, Atmospheric, Surrealism, Style of Dangiuz and Soufiane Idrassi --Watermark, Noise, Compression\",\n",
        "\t\"Futuristic Scifi (Science Fiction Inspired)\": \"Photorealistic, Highly Detailed Illustration, Digitial Painting, Science Fiction, Scifi, Advanced Technology, Intricately Designed, Machinery, AI Artificial Intelligence, Androids, Deep Space, Energy Shields, Z-Space, Post-Human, Quantum, Utopian, Volumetric Lighting, Cinematic, by Ilya Kuvshinov and Aaron Jasinski --Watermark, Border, Frame, Noise\",\n",
        "    \"Gallic (Inspired by Celtic, Gallic, and Gaulish Cultures)\": \"Photorealistic, Digital Art, High Qualtiy, Dark Color Schemes, Gaulish and Celtic Theme, Murky and Atmospheric, Cinematic Lighting, Volumetrics, God Rays, Light Shafts, Particles and Dust in the Air, Elaborate Gallic Designs --Watermark, Border, Frame\",\n",
        "    \"Gigercraft (H.R. Giger and H.P. Lovecraft Inspired)\": \"Sience Fiction, Scifi Theme, Neutral Color Scheme, Organic Growth, Segmentation, Glistening, Wet Surfaces, Dark Atmosphere, Cinematic Lighting, Volumetric Lighting, Extraterrestrial, in the Style of H.R. Giger and H. P. Lovecraft and Dariusz Zawadzki -- Watermark, Image Compression, Film Grain, Noise\",\n",
        "    \"Ink & Watercolor (Zhang QuanZong Inspired)\": \"Photorealistic, Hyperrealism, Highly Detailed, Shaded Colors, Poetic Painting, Ink and Watercolor Influence, Ink and Watercolour, by Zhang QuanZong and Jing Hao (Hongguzi), High Quality, HD, Ornate and Elaborate Inkwork, Vibrant Colors --Watermark, Image Compression, Noise, Western art\",\n",
        "    \"Macabre (Midjourney Inspired)\": \"dark color scheme, grunge macabre aesthetic smudging style dark atmosphere bokeh evil painting --Watermark\",\n",
        "\t\"Medieval\": \"Photorealistic, Medieval Theme, Dark nature aesthetic, Atmospheric Lighting, Ambient Lighting, Volumetric Lighting, lightly smokey air, Archaic, Gothic Architecture, Feudal Theme, Anglo-Saxon Theme --Watermark, Image Compression, Noise, Film Graine\",\n",
        "    \"Modern Religious (Christian Art Inspired)\": \"modern, highly detailed, elaborate, prestine clarity holy aesthetic digital painting heavenly atmosphere bokeh ethereal painting divine hazey --Watermark\",\n",
        "\t\"Oil (Impressionist)\": \"Oil Painting, Brush Strokes, Canvas Texture, Textured Paint, Range of Color, Oil Canvas Style, Grainy Brush Strokes, Large Brush Strokes, Impressionist --Watermark\",\n",
        "\t\"Oil (Naturalist)\": \"Naturalistic Style, Realistic Oil Painting, Highly Detailed, Realism,  Fine Art, Chiaroscuro Style, Campitura --Watermark\",\n",
        "\t\"Organic Ornate (Elaborate Decorative Style)\": \"Photorealistic, 3D Matte, by ellen jewett, tomasz alen kopera and Justin Gerard, symmetrical features, ominous, solemn, magical realism, texture, intricate, ornate, royally decorated, Halo, Gilding, Gilded, whirling smoke, particles, gold adornements, white splendid fabric, radiant colors, artstation, volumetric lighting, micro details, 3d sculpture, ray tracing --Watermark, Picture Frame\",\n",
        "    \"Pen & Pencil\": \"hyperrealistic sketch, high relief sketch, detailed lines, pencil lines, realism, shading lines, pen on paper, well defined --Watermark\",\n",
        "\t\"Photorealistic\": \"photograph, realistic, photorealistic, real life, photography, bokeh, lens attenuation, chromatic aberration, realistic color scheme, by Getty Images --Watermark, Brushwork, Style of Drawing, Style of Painting\",\n",
        "\t\"Post-Apocalyptic (Wasteland-like Inspired)\": \"Post-Apocalyptic, Overgrown World, Wasteland, Ruins and Debris, Naturalist Color Scheme, Volumetric Lighting, Cinematic Lighting, Atmospheric, Style of James Chadderton, and Diego Matiz --Watermark\",\n",
        "\t\"Pop Art (High Contrast Color Mixing)\": \"Pop Art, Vivid Color Scheme, Stylized Color, Abstract Brushwork, Digital Painting, Pop culture, Surreal, Highly Detailed, Punky, Splat, Pow, Bam --Watermark\",\n",
        "\t\"Prismatic Universe (Vivid Rainbow Colors)\": \"Photorealistic, Digital Painting, Quantum Universe, Quantum Energy, Made out of Prismatic Crystals, Chromatic Aberration, Prism Colors, Emitting Energy, Celestial, Etherreal, by Ilya Kuvshinov and Ellen Jewett, Prism Color Scheme, Volumetric Lighting, Cinematic, High Quality, High Resolution, Light Shafts, God Rays --Watermark, Image Compression, Noise, Frame, Border\",\n",
        "    \"Regal Imperial (Decorative Royal Accents)\": \"Imperial Regal Style, Gilded by Golden Wheat and Barley, Adorned in Gemstones, Gold and Silver Accent, 3D Matte, by Ilya Kuvshinov, Eve Ventrue, and Aaron Jasinski, ArtStation, CGSociety, elaborate detailed adornment, royal accent, regal features, atmospheric, cinematic, volumetric lighting, supple complexion --Watermark\",\n",
        "    \"Trippy (Psychedelic Art Inspired)\": \"Photorealistic Mandelbrot Set, Beautiful 3D Fractals, Fractalizations, 3d smooth Kaleidoscopes, Realistic Psychedelic Patterns --Watermark, Image Compression, Film Grain, Noise\",\n",
        "    \"Vivid Disco (Glamour in Dynamic Colors)\": \"Photorealistic, Vivid Disco Color Scheme, Color Mixing, High Contrast, Highly Detailed, Poppy, Lens Flares, Shine, Sparkle, Glitter, Style of Ilya Kuvshinov --Watermark, Compression, Noise\"\n",
        "}\n",
        "\n",
        "# Setup param scraper\n",
        "scraper = paramScraper(settings_template, globals())\n",
        "scraper.scrape('setup')\n",
        "\n",
        "last_pipe_type = None\n",
        "last_model_type = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucr5_i21xSjv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <a name=\"settingsdiffuse\"><font size=\"5\" color=\"default\">**Settings & Diffuse**</font></a>\n",
        "\n",
        "SAVE_SETTING_FILE = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### <a name=\"promptsetup\">**Prompt Setup**</a>\n",
        "#@markdown <font size=\"3\">Prompts support [Noodle Soup Prompts](https://github.com/WASasquatch/noodle-soup-prompts/wiki/Terminology-Reference) \\([NSP Prompt Generator](https://rebrand.ly/noodle-soup-prompts)\\)</font><br>\n",
        "#@markdown <font size=\"3\">You can split your prompt into positive and negative by using `--` Example: `positive prompt here --negative prompt here`\n",
        "PROMPT = \"A stylish beautiful 3d render portrait of a _noun-emote_ cat in a _color_ space helmet on the moon --dog\" #@param {type:'string'}\n",
        "PROMPT_FILE = '' #@param {type: 'string'}\n",
        "#@markdown <font size=\"3\">`PROMPT_FILE` is a optional text file that contains a prompt ***per*** line. If you use a regular `PROMPT` as well, it will be added as the first prompt in series.</font>\n",
        "PROMPT_STYLE = 'None' #@param['None', 'Anime (Japanese Animation Inspired)', 'Cartoon (Matt Groening)', 'Cartoon (Seth McFarlane)', 'Cosmic (Space Art Style)', 'Cyberpunk', 'Dragan (Andrzej Dragan Inspired)', 'Dystopian (Bleak)', 'Exopunk (Extreterrestrial Cyberpunk Inspired)', 'Futuristic Scifi (Science Fiction Inspired)', 'Gallic (Inspired by Celtic, Gallic, and Gaulish Cultures)', 'Gigercraft (H.R. Giger and H.P. Lovecraft Inspired)', 'Ink & Watercolor (Zhang QuanZong Inspired)', 'Macabre (Midjourney Inspired)', 'Medieval (Medieval Theme Inspired)', 'Modern Religious (Christian Art Inspired)', 'Oil (Impressionist)', 'Oil (Naturalist)', 'Organic Ornate (Elaborate Decorative Style)', 'Pen & Pencil', 'Photorealistic', 'Post-Apocalyptic (Wasteland-like Inspired)', 'Pop Art (High Contrast Color Mixing)', 'Prismatic Universe (Vivid Rainbow Colors)', 'Regal Imperial (Decorative Royal Accents)', 'Trippy (Psychedelic Art Inspired)', 'Vivid Disco (Glamour in Dynamic Colors)']\n",
        "#@markdown <font size=\"3\">Apply a style to your prompt. Focus on the prompt, not the style!\n",
        "NEW_NSP_ON_ITERATION = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Whether to generate NSP once, or on each iteration. Check this if you want each iteration to have a freshly cooked noodle prompt.</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### <a name=\"initsetup\">**Init Image Setup**</a>\n",
        "INIT_IMAGE = \"\" #@param {type: 'string'}\n",
        "INIT_MASK = \"\" #@param {type: 'string'}\n",
        "#@markdown <font size=\"3\">`INIT_IMAGE` and `INIT_MASK` accepts the following formats</font>\n",
        "#@markdown - <font size=\"3\">A single local, or remote image</font>\n",
        "#@markdown - <font size=\"3\">A `.txt` file containing a single local, or remote image ***per*** line.</font>\n",
        "#@markdown - <font size=\"3\">A path to a local folder containing images.</font>\n",
        "\n",
        "#@markdown <font size=\"3\">**Note:** You can use a `PROMPT_FILE` with `INIT_IMAGE`. If you have more images than prompts, it will use the last prompt for all remaining `INIT_IMAGE`. Additionally, if there are more `INIT_IMAGE`'s then `INIT_MASK` the last `INIT_MASK` will be used for the remaining `INIT_IAMGE`</font> \n",
        "INIT_FILTERS = '' #@param{type: 'string'}\n",
        "#@markdown <font size=\"3\">Filter init images in a file or folder by these filters seperated by a comma. Ex: `nature,outdoors,travel`\n",
        "\n",
        "INIT_SCALE = 0.8 #@param{type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown <font size=\"3\">**Note:** Scale of init image from 0 to 1. Lower values adhear more to the image.</font>\n",
        "\n",
        "#@markdown ---\n",
        "RECURSIVE_EVOLUTION = False #@param{type:'boolean'}\n",
        "#@markdown <font size=\"3\">Automatically start a img2img diffusion run with the diffusion result from the previous text2img run. Will run for `NUM_ITERS` iterations.</font>\n",
        "#@markdown <font size=\"3\">**Note:** Currently only supports Text-to-Image as a starting point, and doesn't support batch prompts.</font>\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### <a name=\"diffusionsettings\">**Diffusion Settings**</a>\n",
        "MODEL_ID = 'CompVis/stable-diffusion-v1-4' #@param [\"CompVis/stable-diffusion-v1-4\", \"CompVis/stable-diffusion-v1-3\",\"CompVis/stable-diffusion-v1-2\",\"CompVis/stable-diffusion-v1-1\",\"hakurei/waifu-diffusion\"]{allow-input: true}\n",
        "#@markdown If using `CACHE_PIPELINES` you will need to run `RECACHE_PIPES` once when switching `MODEL_ID`. Allows custom input (for HF models not listed)\n",
        "REDOWNLOAD_MODEL = False #@param{type: 'boolean'}\n",
        "SAMPLER = 'DEFAULT' #@param [\"DEFAULT\", \"PNDM\", \"LMS\", \"DDIM\"]\n",
        "DDIM_ETA = 0.65 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown <font size=\"3\">`DDIM_ETA` only applies to the DDIM sampler.</font>\n",
        "STEPS = 50 #@param {type:\"slider\", min:5, max:500, step:5} \n",
        "#@markdown <font size=\"3\">Diffusion steps determines the quality of the final image</font>\n",
        "SEED = 0 #@param {type:'raw'}\n",
        "#@markdown <font size=\"3\">The seed used for the generation. System max value is `9999999999999999`. Leave at `0` for random. You can also enter text encapulated by semi-quotes such as: `'RockyCanyon'`</font>\n",
        "MAX_SEED = 'system_max' #@param{type:'raw'}\n",
        "#@markdown <font size=\"3\">Use `'system_max'` (with semi-quotes) for the maximum seed `int`, or define the max random int size (maximum integer length of 16 digits).\n",
        "INCREMENT_ITERATION_SEED = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Increment seed on each iteration.</font>\n",
        "NUM_ITERS = 5 #@param {type:\"slider\", min:1, max:1000, step:1} \n",
        "#@markdown <font size=\"3\">Number of iterations for a given prompt or init image.</font>\n",
        "WIDTH = 512 #@param {type:\"slider\", min:256, max:4096, step:64}\n",
        "HEIGHT = 640 #@param {type:\"slider\", min:256, max:4096, step:64}\n",
        "SCALE = 13.5 #@param {type:\"slider\", min:0, max:25, step:0.1}\n",
        "#@markdown <font size=\"3\">The CFG `SCALE` determines how closely a generation follows the prompt, or improvisation. Lower values will try to adhear to your prompt.</font>\n",
        "PRECISION = \"autocast\" #@param [\"full\",\"autocast\"]\n",
        "#@markdown <font size=\"3\">If you're using the `LOW_VRAM_PATCH` you <b>must</b> use `autocast`</font><br>\n",
        "IMAGES_FOLDER = \"Dystopian_House\" #@param {type: 'string'}\n",
        "#@markdown <font size=\"3\">Define a custom folder to saves images within your `images_out` folder. Example: `CAR_CONCEPTS`</font>\n",
        "#@markdown <font size=\"3\">**Note:** Path: `/content/Stable_Diffusion/images_out` or with Google Drive `/content/drive/MyDrive/AI/Stable_Diffusion/images_out`</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### <a name=\"cachepipes\">**Cache Pipelines**</a>\n",
        "#@markdown <font size=\"3\">Cached pipes store the loaded model in memory, as well as the configured Stable Diffusion pipeline to a object stored on disk. These files can be large. The benefit is once pipes are cached, switching between them takes less than 4 seconds. By contrast, switching pipes from memory in the vanillas Stable Diffusion can take up to 38 seconds. That means just doing 4 images spread across txt2img, and img2img, cached pipes could save you over a minute in time!</font>\n",
        "CACHE_PIPELINES = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Whether to cache pipes to disk and load on demand.</font>\n",
        "RECACHE_PIPES = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Recache pipelines. Required if switching diffusion models, or upgrading the pipe to a new version of diffusers.</font>\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <font size=\"3\">**NOTE:** If you're having trouble loading pipes to start diffusions, check this and run this cell again.</font><br>\n",
        "SKIP_DIFFUSION_RUN = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Skip diffusion run ***If*** `INIT_IMAGE` ***is defined*** to process images.</font>\n",
        "ENABLE_NSFW_FILTER = False #@param {type:\"boolean\"}\n",
        "#@markdown <font size=\"3\">`ENABLE_NSFW_FILTER`: Will return a blurred image for content flagged as NSFW</font>\n",
        "ENABLE_ATTENTION_SLICES = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Enable attention slices to better utilization of available memory at the cost of diffusion speed.</font>\n",
        "LOW_VRAM_PATCH = True #@param {type:\"boolean\"}\n",
        "#@markdown <font size=\"3\">You may need this if you're using a GPU with ~16GB VRAM. **Note:** This appplies to non-cached pipes.</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### <a name=\"upscalers\">**General Upscaling Settings**</a>\n",
        "#@markdown <font size=\"3\">`IMAGE_UPSCALER`: may not work at resolutions above 512x768/768x512 on GPUs with ~16GB VRAM. Try using ESRGAN in CPU Mode if you're having issues.<br>**Note:** GFPGAN/CodeFormer is good for faces only.</font>\n",
        "IMAGE_UPSCALER = \"CodeFormer\" #@param [\"None\",\"GFPGAN\",\"Enhanced Real-ESRGAN\", \"GFPGAN + Enhanced ESRGAN\", \"CodeFormer\", \"CodeFormer + Enhanced ESRGAN\"]\n",
        "UPSCALE_AMOUNT = 2 #@param {type:\"slider\", min:2, max:8, step:2}\n",
        "ESRGAN_MODE = 'CUDA' #@param ['CUDA', 'CPU']\n",
        "#@markdown <font size=\"3\">Real-ESRGAN Device Mode. CUDA is GPU.\n",
        "#@markdown ---\n",
        "#@markdown #### **CodeFormer Upscaling Settings**\n",
        "CODEFORMER_UPSCALE_AMOUNT = 1 #@param {type: 'number'}\n",
        "#@markdown <font size=\"3\">`CF_UPSCALE_AMOUNT` only applies to CodeFormer. Defined the upscale factor for CodeFormer.\n",
        "CODEFORMER_FIDELITY = 0.6 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "#@markdown <font size=\"3\">`CODEFORMER_FIDELITY`: only applies to CodeFormer. Balance the quality (lower number) and fidelity (higher number)</font><br>\n",
        "\n",
        "if CODEFORMER_UPSCALE_AMOUNT <= 0:\n",
        "    CODEFORMER_UPSCALE_AMOUNT = 1\n",
        "else:\n",
        "    CODEFORMER_UPSCALE_AMOUNT = closest_value([1,2,4,8],CODEFORMER_UPSCALE_AMOUNT)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### <a name=\"imageprocessors\">**Image Processor Setup**</a>\n",
        "KEEP_ONLY_FINAL_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Delete original images after final upscaling.</font>\n",
        "SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN = True #@param{type:'boolean'}\n",
        "#@markdown <font size=\"3\">Scale down enhanced images. Useful if you are also using Real-ESRGAN. This will preserve your upscale factor for Real-ESRGAN after GFPGAN or CodeFormer.</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"sharpen\">Sharpen Image</a>\n",
        "#@markdown <font size=\"3\">Sharpen the base diffusion image before upscsaling.</font>\n",
        "SHARPEN_AMOUNT = 1 #@param{type:'slider', min:0, max:3, step:1}\n",
        "#@markdown <font size=\"3\">Sharpen iteration amount. `0` for no sharpen.</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"kromo\">Kromo Chromatic Aberration</a>\n",
        "CA_DIFFUSE_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Apply Chromatic Aberration to the base diffusion image (pre sharpen if enabled)</font>\n",
        "CA_STRENGTH = 0.1 #@param {type:\"slider\", min:0, max:5, step:0.1}\n",
        "#@markdown <font size=\"3\">Chromatic Aberration strength</font>\n",
        "CA_JITTER = 1 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "#@markdown <font size=\"3\">Chromatic Aberration set channel offset pixels</font>\n",
        "CA_OVERLAY = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown <font size=\"3\">Alpha of original image overlay.</font>\n",
        "CA_NO_RADIAL_BLUR = True #@param{type: 'boolean'}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"median\">Median Filter Image</a>\n",
        "MEDIAN_FILTER_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Apply a Median Filter effect to the diffusion image. This can be tuned similar to a surface blur for reducing detail.</font>\n",
        "MEDIAN_DIAMETER = 2.5 #@param{type:'slider', min:0.1, max:100, step:0.1}\n",
        "#@markdown <font size=\"3\">Radius of the median filtering effect</font>\n",
        "MEDIAN_SIGMA_COLOR = 75 #@param{type: 'number'}\n",
        "#@markdown <font size=\"3\">Sigma Color filters sigma in the color space. A larger value means that farther colors within the pixel neighborhood will be mixed together, resulting in larger areas of semi-equal color.</font>\n",
        "MEDIAN_SIGMA_SPACE = 75 #@param{type: 'number'}\n",
        "#@markdown <font size=\"3\">Sigma Space silters the sigma in the coordinate space. A larger value means that farther pixels will influence each other as long as their colors are close enough.</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"midas\">MiDaS Depth Map</a>\n",
        "GENERATE_MIDAS_DEPTH = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Generate a MiDaS Depth Approximation from the diffusion result.</font>\n",
        "SAVE_MIDAS_DEPTH = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Save MiDaS depth approximation.</font>\n",
        "MIDAS_TYPE = \"DPT_Large\" #@param [\"DPT_Large\",\"DPT_Hybrid\",\"MiDaS_small\"]\n",
        "#@markdown <font size=\"3\">`MIDAS_TYPE` determines the model to use for depth approximation.</font>\n",
        "MIDAS_MODE = \"CPU\" #@param [\"CPU\",\"CUDA\"]\n",
        "#@markdown <font size=\"3\">**CPU Mode:** If you get: \"`RuntimeError: \"linspace_cpu\" not implemented for 'Half'`\" something has changed with CPU and you need to disconnect/reconnect (Google Colab)</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"fdof\">Fake Depth of Field Filter</a>\n",
        "FDOF_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Apply Fake Depth of Field to the image based on the MiDaS Depth Map</font>\n",
        "FDOF_REPLACE_IMAGE = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Replace original diffusion image saved to disk with FDOF image. This will also pipe the image through for upscalers.</font>\n",
        "FDOF_RADIUS = 9 #@param {type:'slider', min: 0.1, max:100, step:0.1}\n",
        "#@markdown <font size=\"3\">Depth of Field Blur Radius\n",
        "FDOF_SAMPLES = 1 #@param{type:'slider', min:1, max:5, step:1}\n",
        "#@markdown <font size=\"3\">Resample the image with DOF (can create a stronger DOF effect based on the MiDas Depth Map)</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"tileable\">Tilable Seamless Image</a>\n",
        "TILEABLE_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Process the image as a seamless tileable texture.</font>\n",
        "TILED = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Tile the image 2x2 (Ex a 512x512 image would be tiled to 1024x1024)</font>\n",
        "TILE_OVERLAP = 0.1 #@param{type:'slider', min:0.01, max:1.0, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #### <a name=\"clipinterrogator\">CLIP Interrogator</a>\n",
        "#@markdown <font size=\"3\">CLIP Interrogator requires a substantial chunk of GPU VRAM, and may not be suited for low VRAM cards while running diffusions. Use at your own risk.<br />Using this for init_images with `SKIP_DIFFUSION_RUN` enabled allows you to batch interrogate images to scrape prompt ideas.</font>\n",
        "INTERROGATE_INIT_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Interrogate `INIT_IMAGE`</font>\n",
        "INTERROGATE_DIFFUSION_IMAGE = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Interrogate diffusion result after generation.</font>\n",
        "\n",
        "#@markdown **Interrogator CLIP Models**\n",
        "ViTB32 = False #@param{type:\"boolean\"}\n",
        "ViTB16 = False #@param{type:\"boolean\"}\n",
        "ViTL14 = True #@param{type:\"boolean\"}\n",
        "ViTL14_336px = False #@param{type:\"boolean\"}\n",
        "RN101 = False #@param{type:\"boolean\"}\n",
        "RN50 = False #@param{type:\"boolean\"}\n",
        "RN50x4 = False #@param{type:\"boolean\"}\n",
        "RN50x16 = False #@param{type:\"boolean\"}\n",
        "RN50x64 = False #@param{type:\"boolean\"}\n",
        "#@markdown <font size=\"3\">These models are only relevant if you're interrogating init images or diffusion results with CLIP Interrogator.</font>\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### <a name=\"othersettings\">**Other Diffusion Settings**</a>\n",
        "IMAGES_DISPLAY_ABOVE_LOG = False #@param{type: 'boolean'}\n",
        "#@markdown Display organized JS Images above log output, not below.</font>\n",
        "USE_BASIC_IMAGE_DISPLAY = False #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Use basic image output instead of organized JS Image Output</font>\n",
        "CLEAR_LOG_BETWEEN_ITERATIONS = True #@param{type: 'boolean'}\n",
        "#@markdown <font size=\"3\">Clear the output log between each iteration. (Organized JS Mode Only)</font>\n",
        "\n",
        "clean_env()\n",
        "last_diffusion_filedir = None\n",
        "\n",
        "download_model(MODEL_ID, REDOWNLOAD_MODEL)\n",
        "\n",
        "ESRGAN_MODE = ESRGAN_MODE.lower()\n",
        "\n",
        "if LOW_VRAM_PATCH and PRECISION is not 'autocast': \n",
        "    print(f\"PRECISION must be 'autocast' when running in low vram compatibility mode! Defaulting to autocast...\")\n",
        "    PRECISION = 'autocast'\n",
        "\n",
        "precision_scope = autocast if PRECISION is 'autocast' else nullcontext\n",
        "\n",
        "# Max Seed and Custom Seed Setup\n",
        "if MAX_SEED is 'system_max':\n",
        "    MAX_SEED = 9999999999999999\n",
        "else:\n",
        "    MAX_SEED = int(MAX_SEED)\n",
        "\n",
        "text_seed = None\n",
        "if type(SEED) is str:\n",
        "    text_seed = SEED\n",
        "    SEED = text2seed(SEED, 16)\n",
        "else:\n",
        "    SEED = int(SEED)\n",
        "\n",
        "ORIG_SEED = SEED\n",
        "\n",
        "os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "GDRIVE_OUT_PATH = f'{GDRIVE_WORKDIR}/images_out/{IMAGES_FOLDER}'\n",
        "if USE_DRIVE_FOR_PICS:\n",
        "    if not os.path.exists(GDRIVE_OUT_PATH):\n",
        "        os.makedirs(GDRIVE_OUT_PATH)\n",
        "    OUTDIR = GDRIVE_OUT_PATH        \n",
        "\n",
        "# JavaScript Compatible Boolean\n",
        "if IMAGES_DISPLAY_ABOVE_LOG:\n",
        "    IMAGES_DISPLAY_ABOVE_LOG = 1\n",
        "else:\n",
        "    IMAGES_DISPLAY_ABOVE_LOG = 0\n",
        "\n",
        "print(f\":open_file_folder: Images Output Directory: {OUTDIR}\\n\")\n",
        "\n",
        "if RECURSIVE_EVOLUTION is True:\n",
        "    print(\":gear: Recursive Evolution is Enabled\")\n",
        "\n",
        "# Check Upscaling Mode\n",
        "if IMAGE_UPSCALER == 'GFPGAN' and not INSTALL_GFPGAN:\n",
        "    print(\":WARNING: GFPGAN Face Restoration is not installed. Disabling upscaling...\")\n",
        "    IMAGE_UPSCALER = 'None'\n",
        "if IMAGE_UPSCALER == 'Enhanced Real-ESRGAN' and not INSTALL_ESRGAN:\n",
        "    print(\":WARNING: Real-ESRGAN is not installed. Disabling upscaling...\")\n",
        "    IMAGE_UPSCALER = 'None'\n",
        "if IMAGE_UPSCALER == 'CodeFormer' and not INSTALL_CODEFORMER:\n",
        "    print(\":WARNING: CodeFormer is not installed! Disabling upscaling...\")\n",
        "    IMAGE_UPSCALER = 'None'\n",
        "if IMAGE_UPSCALER == 'GFPGAN + Enhanced ESRGAN':\n",
        "    if not INSTALL_GFPGAN and INSTALL_ESRGAN:\n",
        "        print(\":WARNING: GFPGAN is not installed, defaulting to Real-ESRGAN...\")\n",
        "        IMAGE_UPSCALER = 'Enhanced Real-ESRGAN'\n",
        "    if not INSTALL_ESRGAN and INSTALL_GFPGAN:\n",
        "        print(\":WARNING: Real-ESRGAN is not installed, defaulting to GFPGAN...\")\n",
        "        IMAGE_UPSCALER = 'GFPGAN'\n",
        "if IMAGE_UPSCALER == 'CodeFormer + Enhanced ESRGAN':\n",
        "    if not INSTALL_CODEFORMER and INSTALL_ESRGAN:\n",
        "        print(\":WARNING: CodeFormer is not installed, defaulting to Real-ESRGAN...\")\n",
        "        IMAGE_UPSCALER = 'Enhanced Real-ESRGAN'\n",
        "    if not INSTALL_ESRGAN and INSTALL_CODEFORMER:\n",
        "        print(\":WARNING: Real-ESRGAN is not installed, defaulting to CodeFormer...\")\n",
        "        IMAGE_UPSCALER = 'CodeFormer'\n",
        "\n",
        "# Nearest value to UPSCALE_AMOUNT\n",
        "nearest_value = closest_value([2,4,8],UPSCALE_AMOUNT)\n",
        "\n",
        "scraper.updateGlobals(globals())\n",
        "scraper.scrape('upscalers')\n",
        "scraper.scrape('image_processing')\n",
        "scraper.scrape('other_settings')\n",
        "\n",
        "# Diffuse Function\n",
        "def diffuse_run():\n",
        "\n",
        "    clean_env()\n",
        "\n",
        "    global RECACHE_PIPES, CACHE_PIPELINES, PROMPT, PROMPT_STYLE, SEED, UPSCALE_AMOUNT, GENERATE_MIDAS_DEPTH, FDOF_IMAGE, RECURSIVE_EVOLUTION, last_diffusion_filedir, init, original_init, original_mask, last_model_type, pipe_type, pipe_cache\n",
        "    if not CACHE_PIPELINES: global pipe\n",
        "    else: pipe = None\n",
        "\n",
        "    if ORIG_SEED is 0 and SEED is 0:\n",
        "        SEED = random.randint(0,MAX_SEED)\n",
        "    else:\n",
        "        if INCREMENT_ITERATION_SEED and iteration > 0:\n",
        "            SEED += 1\n",
        "\n",
        "    if not os.path.exists(OUTDIR):\n",
        "        os.makedirs(OUTDIR)\n",
        "\n",
        "    scraper.updateGlobals(globals())\n",
        "    scraper.scrape('prompts')\n",
        "    scraper.scrape('inits')\n",
        "    scraper.scrape('diffusion_settings')\n",
        "\n",
        "    epoch_time = int(time.time())\n",
        "    if not SKIP_DIFFUSION_RUN:\n",
        "\n",
        "        prompt_suffix = f' (Prompt Style: {PROMPT_STYLE})' if style.__contains__(PROMPT_STYLE) else ''\n",
        "        encoded_seed = f' (Encoded from: {text_seed})' if text_seed else ''\n",
        "        gen_seed = torch.Generator(\"cuda\").manual_seed(SEED)\n",
        "        eta_prev = f' (ETA: {DDIM_ETA})' if SAMPLER is 'DDIM' else ''\n",
        "        print(f\"\\n\\033[1mBatch {(i+1)}/{len(ITERATE_THIS)} Iteration {(iteration+1)}/{NUM_ITERS}\\033[0m\")\n",
        "        print(f':seedling: Seed: \\033[1m{SEED}{encoded_seed}\\033[0m, :triangular_ruler: Scale: \\033[1m{SCALE}\\033[0m, :footprints: Steps: \\033[1m{STEPS}\\033[0m, :artist_palette: Sampler: {SAMPLER}{eta_prev} :framed_picture: Resolution: \\033[1m{WIDTH}x{HEIGHT}')\n",
        "        midas_prev = f' (Type: \\033[1m{MIDAS_TYPE}\\033[0m, Mode: \\033[1m{MIDAS_MODE}\\033[0m)' if GENERATE_MIDAS_DEPTH else ''\n",
        "        ca_prev = f' (Strength: \\033[1m{CA_STRENGTH}\\033[0m, Jitter: \\033[1m{CA_JITTER}\\033[0m, Overlay: \\033[1m{CA_OVERLAY}\\033[0m, No Radial Blur: \\033[1m{CA_NO_RADIAL_BLUR}\\033[0m)\\n' if CA_DIFFUSE_IMAGE else ''\n",
        "        print(f'Scale Down: \\033[1m{SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN}\\033[0m, Sharpen Passes: \\033[1m{SHARPEN_AMOUNT}\\033[0m, Chromatic Aberration: \\033[1m{CA_DIFFUSE_IMAGE}\\033[0m{ca_prev} Depth Export: \\033[1m{GENERATE_MIDAS_DEPTH}\\033[0m{midas_prev}\\n')\n",
        "        print(f\"\\033[0m:black_nib: Prompt{prompt_suffix}:\\033[1m\")\n",
        "        printPrompt(PROMPT)\n",
        "        print(\"\\033[0m\\n\")\n",
        "\n",
        "        # Parse Prompt\n",
        "        NEG_PROMPT = ''\n",
        "        if '--' in PROMPT:\n",
        "            pparts = [p.strip() for p in PROMPT.split('--')]; PROMPT = pparts[0]; NEG_PROMPT = pparts[1]\n",
        "\n",
        "        # Apply Style\n",
        "        if PROMPT_STYLE.lower() not in [None, 'none', ''] and style.__contains__(PROMPT_STYLE):\n",
        "            sparts = [s.strip() for s in style[PROMPT_STYLE].split('--')]; PROMPT += f', {sparts[0]}'; NEG_PROMPT += f', {sparts[1]}'\n",
        "\n",
        "        # Load Cached Pipelines\n",
        "        if CACHE_PIPELINES:\n",
        "            if MODEL_ID is not last_model_type:\n",
        "                RECACHE_PIPE = True\n",
        "            clean_env()\n",
        "            stt = int(time.time())\n",
        "            print(':gear: Loading Stable Diffusion Pipeline from cache...')\n",
        "            pipe = cache_pipes(pipe_type, MODEL_ID, model_cache, pipe_cache)\n",
        "            if pipe is None:\n",
        "                raise Exception(\":warning: Unable to load pipe from cache!\")\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f':check_mark_button: Pipeline loaded in {fnt}')\n",
        "\n",
        "        if RECURSIVE_EVOLUTION and last_diffusion_filedir is not None:\n",
        "            print(\":information: Found evolution file:\", last_diffusion_filedir)\n",
        "            init = last_diffusion_filedir\n",
        "            try:\n",
        "                from PIL import ImageOps\n",
        "                init = Image.open(fetch(init)).convert(\"RGB\")\n",
        "                original_init = init.copy()\n",
        "                init = preprocess(init)\n",
        "                pipe_type = 'img2img'\n",
        "                if not CACHE_PIPELINES:\n",
        "                    try:\n",
        "                        if pipe:\n",
        "                            print(\":computer_disk: Pipeline already in memory. Starting diffusion environment...\\n\")\n",
        "                    except NameError:\n",
        "                        pipe = setup_pipes(pipe_type, MODEL_ID, model_cache)\n",
        "                        pass\n",
        "                    if type(pipe) is not StableDiffusionImg2ImgPipeline:\n",
        "                        print(\":hourglass_not_done: Switching pipeline to Image-to-Image for Evolution...\")\n",
        "                        pipe = setup_pipes(pipe_type, MODEL_ID, model_cache)\n",
        "                else:\n",
        "                    if MODEL_ID is not last_model_type:\n",
        "                        RECACHE_PIPE = True\n",
        "                    #print(\":hourglass_not_done: Switching pipeline cache to Image-to-Image for Evolution...\")\n",
        "                    pipe = cache_pipes(pipe_type, MODEL_ID, model_cache, pipe_cache)\n",
        "            except Exception as e:\n",
        "                raise e\n",
        "\n",
        "    if init is not None:\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print(\"Resized Init Image:\")\n",
        "            display(original_init)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Resized Init Image B: {(i+1)} I: {(iteration+1)}', original_init)\n",
        "        if SKIP_DIFFUSION_RUN:\n",
        "            image = original_init.copy()\n",
        "        if INTERROGATE_INIT_IMAGE:\n",
        "            do_interrogate(image)\n",
        "            scraper.updateGlobals(globals())\n",
        "            scraper.scrape('clip_interrogator')\n",
        "\n",
        "    if mask is not None:\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print(\"Resized Mask Image:\")\n",
        "            display(original_mask)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Resized Mask Image B: {(i+1)} I: {(iteration+1)}', original_mask)\n",
        "\n",
        "    # Setup Pipes\n",
        "    if not SKIP_DIFFUSION_RUN:\n",
        "\n",
        "        if SAMPLER is 'DEFAULT':\n",
        "            pipe.scheduler = PNDMScheduler (\n",
        "                trained_betas= None,\n",
        "                beta_end= 0.012,\n",
        "                beta_schedule= \"scaled_linear\",\n",
        "                beta_start= 0.00085,\n",
        "                num_train_timesteps= 1000,\n",
        "                skip_prk_steps= True\n",
        "            )\n",
        "        if SAMPLER == 'PNDM':\n",
        "            pipe.scheduler = PNDMScheduler(\n",
        "                trained_betas= None,\n",
        "                beta_start=0.00085, \n",
        "                beta_end=0.012, \n",
        "                beta_schedule=\"scaled_linear\", \n",
        "                num_train_timesteps=1000\n",
        "            )\n",
        "        elif SAMPLER == 'LMS':\n",
        "            pipe.scheduler = LMSDiscreteScheduler(\n",
        "                trained_betas= None,\n",
        "                beta_start=0.00085,\n",
        "                beta_end=0.012,\n",
        "                beta_schedule=\"scaled_linear\",\n",
        "                num_train_timesteps=1000\n",
        "            )\n",
        "        elif SAMPLER == 'DDIM':\n",
        "            pipe.scheduler = DDIMScheduler(\n",
        "                trained_betas= None,\n",
        "                beta_start=0.00085,\n",
        "                beta_end=0.012,\n",
        "                beta_schedule=\"scaled_linear\", \n",
        "                clip_sample=False,\n",
        "                set_alpha_to_one=False\n",
        "            )\n",
        "\n",
        "        if ENABLE_ATTENTION_SLICES:\n",
        "            print(':gear: Attention Slices Enabled')\n",
        "            pipe.enable_attention_slicing()\n",
        "        else:\n",
        "            pipe.disable_attention_slicing()\n",
        "        print(':check_mark_button: Pipeline setup complete.')\n",
        "\n",
        "        # Do diffusion\n",
        "        pipeout = None\n",
        "        last_model_type = MODEL_ID\n",
        "        try:\n",
        "            stt = int(time.time())\n",
        "            print(f\":alembic: Starting Diffusion run with {MODEL_ID}\")\n",
        "            if init is not None:\n",
        "                if mask is not None:\n",
        "                    with autocast(\"cuda\"):\n",
        "                        pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, init_image=init, mask_image=mask, strength=INIT_SCALE, guidance_scale=SCALE, generator=gen_seed)\n",
        "                        image = pipeout[\"sample\"][0]\n",
        "                else:\n",
        "                    with autocast(\"cuda\"):\n",
        "                        pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, init_image=init, strength=INIT_SCALE, guidance_scale=SCALE, generator=gen_seed)\n",
        "                        image = pipeout[\"sample\"][0]\n",
        "            else:\n",
        "                if SAMPLER == 'ddim':\n",
        "                    pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)\n",
        "                    image = pipeout[\"sample\"][0]\n",
        "                else:\n",
        "                    pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, generator=gen_seed)\n",
        "                    image = pipeout[\"sample\"][0]\n",
        "        except BaseException as e:\n",
        "            raise e\n",
        "        finally:\n",
        "            if pipeout and pipeout['nsfw_content_detected'][0] and ENABLE_NSFW_FILTER:\n",
        "                print(\":passport_control: Censoring NSFW content...\")\n",
        "                image = image.filter(ImageFilter.GaussianBlur(radius = 18))\n",
        "            if CACHE_PIPELINES and not SKIP_DIFFUSION_RUN:\n",
        "                del pipeout, pipe\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f':check_mark_button: Diffusion completed in {fnt}')\n",
        "            clean_env()\n",
        "\n",
        "    filename = f'{str(epoch_time)}_scale_{SCALE}_steps_{STEPS}_seed_{SEED}.png'\n",
        "    filedir = f'{OUTDIR}/{filename}'\n",
        "    image.save(filedir)\n",
        "\n",
        "    if RECURSIVE_EVOLUTION:\n",
        "        last_diffusion_filedir = filedir\n",
        "        print(\":information: Setting evolution file to:\", last_diffusion_filedir)\n",
        "        time.sleep(2)\n",
        "\n",
        "    if INTERROGATE_DIFFUSION_IMAGE:\n",
        "        clean_env()\n",
        "        interrogate_image = image.copy()\n",
        "\n",
        "    # Doing FDoF? We need depth output\n",
        "    if FDOF_IMAGE and not GENERATE_MIDAS_DEPTH:\n",
        "        if INSTALL_MIDAS:\n",
        "            GENERATE_MIDAS_DEPTH = True\n",
        "            print(':WARNING: Enabling \\'GENERATE_MIDAS_DEPTH\\' (True) for Depth Approximation necessary for Fake Depth of Field.')\n",
        "        else:\n",
        "            print(':WARNING: Unable to generate Fake Depth of Field! MiDaS Compatibility is not installed! Please enable \\'INSTALL_MIDAS\\' and re-run the setup cell.')\n",
        "            GENERATE_MIDAS_DEPTH = False\n",
        "            FDOF_IMAGE = False\n",
        "\n",
        "    # Do Depth Export\n",
        "    depth_image = None\n",
        "    if INSTALL_MIDAS:\n",
        "        if GENERATE_MIDAS_DEPTH:\n",
        "            stt = int(time.time())\n",
        "            print(\"Approximating diffusion depth...\")\n",
        "            midas = torch.hub.load(\"intel-isl/MiDaS\", MIDAS_TYPE)\n",
        "            device = torch.device(\"cuda\") if torch.cuda.is_available() and MIDAS_MODE is 'CUDA' else torch.device(\"cpu\")\n",
        "\n",
        "            midas.to(device).eval()\n",
        "            midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "            if MIDAS_TYPE == \"DPT_Large\" or MIDAS_TYPE == \"DPT_Hybrid\":\n",
        "                transform = midas_transforms.dpt_transform\n",
        "            else:\n",
        "                transform = midas_transforms.small_transform\n",
        "\n",
        "            import cv2\n",
        "            img = cv2.imread(filedir)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            input_batch = transform(img).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = midas(input_batch)\n",
        "\n",
        "                prediction = torch.nn.functional.interpolate(\n",
        "                    prediction.unsqueeze(1),\n",
        "                    size=img.shape[:2],\n",
        "                    mode=\"bicubic\",\n",
        "                    align_corners=False,\n",
        "                ).squeeze()\n",
        "\n",
        "            depth = prediction.cpu().numpy()\n",
        "            depth = (depth * 255 / (np.max(depth)+1)).astype('uint8')\n",
        "            depth_image = Image.fromarray(depth)\n",
        "            if SAVE_MIDAS_DEPTH:\n",
        "                depth_image.save(filedir.replace('.png', '_depth.png'))\n",
        "            del midas, device, midas_transforms\n",
        "            del transform, img, input_batch, prediction, depth\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'Depth approximation completed in {fnt}')\n",
        "            clean_env()\n",
        "\n",
        "    original_displayed = False\n",
        "    # Do Median Filter\n",
        "    if MEDIAN_FILTER_IMAGE:\n",
        "        original_displayed = True\n",
        "        stt = int(time.time())\n",
        "        print('Applying Median Filter...')\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print(\"Original Diffusion Image:\")\n",
        "            display(image)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Original Diffusion B: {(i+1)} I: {(iteration+1)}', image)\n",
        "        image = medianFilter(image, MEDIAN_DIAMETER, MEDIAN_SIGMA_COLOR, MEDIAN_SIGMA_SPACE)\n",
        "        fnt = time_format(int(time.time()) - stt)\n",
        "        print(f'Applied Median Filter in {fnt}')\n",
        "\n",
        "    # Do Chromatic Aberration\n",
        "    if INSTALL_KROMO:\n",
        "        if CA_DIFFUSE_IMAGE:\n",
        "            stt = int(time.time())\n",
        "            res = ''\n",
        "            print(f\"Applying chromatic aberration to result image.\\n\")\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/kromo')\n",
        "            ca_no_blur = '-n ' if CA_NO_RADIAL_BLUR else ''\n",
        "            res += subprocess.run(f'python kromo.py -s {CA_STRENGTH} -j {CA_JITTER} -y {CA_OVERLAY} {ca_no_blur}-o {filedir} {filedir}'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if res.strip() != '':\n",
        "                print(res)\n",
        "            image = Image.open(filedir).resize((WIDTH,HEIGHT))\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            fnt = time_format(int(time.time() - stt))\n",
        "            print(f'Chromatic aberration applied in {fnt}')\n",
        "        clean_env()\n",
        "\n",
        "    # Do Sharpen\n",
        "    if SHARPEN_AMOUNT > 0:\n",
        "        stt = int(time.time())\n",
        "        print(f\"Sharpening diffusion result with {SHARPEN_AMOUNT} passes.\")\n",
        "        image = sharpenImage(image, SHARPEN_AMOUNT)\n",
        "        fnt = time_format(int(time.time()) - stt)\n",
        "        print(f'Sharpening completed in {fnt}')\n",
        "        clean_env()\n",
        "\n",
        "    # Do FDOF\n",
        "    fdof_title = None\n",
        "    if FDOF_IMAGE:\n",
        "        if depth_image:\n",
        "            stt = int(time.time())\n",
        "            print('Applying Fake Depth of Field...')\n",
        "            fdof_image = portraitBlur(image, depth_image, FDOF_RADIUS, FDOF_SAMPLES).convert('RGB')\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'Applied FDOF in {fnt}')\n",
        "            if FDOF_REPLACE_IMAGE or KEEP_ONLY_FINAL_IMAGE:\n",
        "                fdof_title = 'FDOF Image'\n",
        "                if not original_displayed:\n",
        "                    if USE_BASIC_IMAGE_DISPLAY:\n",
        "                        print('Original Diffusion Image:')\n",
        "                        display(image)\n",
        "                    else:\n",
        "                        displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Original Diffusion B: {(i+1)} I: {(iteration+1)}', image)\n",
        "                fdof_image.save(filedir)\n",
        "                image = Image.open(filedir)\n",
        "                fdof_image.close()\n",
        "                del fdof_image \n",
        "        else:\n",
        "            print(f':WARNING: Warning: depth_image is not generated! Is MiDaS compatibility installed?')\n",
        "\n",
        "    # Do Seamless Image\n",
        "    if TILEABLE_IMAGE:\n",
        "        stt = int(time.time())\n",
        "        print(f'Processing tiled seamless image...')\n",
        "        image = image.resize((WIDTH, HEIGHT))\n",
        "        image.save(f'{OUTDIR}/tile_temp.png')\n",
        "        tileFilename = filename.replace('.png','_seamless.png')\n",
        "        seamlessPath = os.path.join(OUTDIR, tileFilename)\n",
        "        tileFlag = f' --tile' if TILED else ''\n",
        "        if GENERATE_MIDAS_DEPTH and depth_image and SAVE_MIDAS_DEPTH:\n",
        "            depth_seamlessPath = os.path.join(OUTDIR, filename.replace('.png','_depth_seamless.png'))\n",
        "            depthFileDir = filedir.replace('.png', '_depth.png')\n",
        "            res = subprocess.run(f'img2texture {depthFileDir} {depth_seamlessPath} --overlap {TILE_OVERLAP}{tileFlag}'.split(' '), capture_output=True, text=True, input=\"y\")\n",
        "        print(f'Saving tiled image to: {seamlessPath}')\n",
        "        res = subprocess.run(f'img2texture {OUTDIR}/tile_temp.png {seamlessPath} --overlap {TILE_OVERLAP}{tileFlag}'.split(' '), capture_output=True, text=True, input=\"y\")\n",
        "        seamless_image = Image.open(seamlessPath).convert('RGB')\n",
        "        tiled_image = Image.open(seamlessPath.replace('.png','_2x2.jpg')).convert('RGB')\n",
        "        os.remove(f'{OUTDIR}/tile_temp.png')\n",
        "        fnt = time_format(int(time.time()) - stt)\n",
        "        print(f'Processed tiled seamless image in {fnt}')\n",
        "\n",
        "    main_img_title = 'SD Image'\n",
        "    if SKIP_DIFFUSION_RUN or original_displayed:\n",
        "        main_img_title = 'Processed Image'\n",
        "    elif fdof_title:\n",
        "        main_img_title = fdof_title\n",
        "\n",
        "    # Display Diffusion Image\n",
        "    if USE_BASIC_IMAGE_DISPLAY:\n",
        "        print(\"Diffusion Image:\")\n",
        "        display(image)\n",
        "    else:\n",
        "        displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'{main_img_title} B: {(i+1)} I: {(iteration+1)}', image)\n",
        "\n",
        "    # Display Depth Image\n",
        "    try:\n",
        "        if depth_image:\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('Depth Map:')\n",
        "                display(depth_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Depth Map B: {(i+1)} I: {(iteration+1)}', depth_image)\n",
        "            depth_image.close()\n",
        "            del depth_image\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    # Display FDOF Image\n",
        "    try:\n",
        "        if fdof_image:\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('FDOF Image:')\n",
        "                display(fdof_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'FDOF B: {(i+1)} I: {(iteration+1)}', fdof_image)\n",
        "            fdof_image.close()\n",
        "            del fdof_image\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    # Display Tiled Seamless Image\n",
        "    try:\n",
        "        if seamless_image:\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('Seamless Image:')\n",
        "                display(seamless_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Seamless Image B: {(i+1)} I: {(iteration+1)}', seamless_image)\n",
        "            seamless_image.close()\n",
        "            del seamless_image\n",
        "    except NameError:\n",
        "        pass\n",
        "    try:\n",
        "        if tiled_image:\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('Tiled Image:')\n",
        "                display(tiled_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Tiled Image B: {(i+1)} I: {(iteration+1)}', tiled_image)\n",
        "            tiled_image.close()\n",
        "            del tiled_image\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    #if 'ESRGAN' in IMAGE_UPSCALER:\n",
        "    #    os.chdir(f\"{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN\")\n",
        "    #    if not os.path.exists(f'weights/RealESRGAN_x{UPSCALE_AMOUNT}.pth'):\n",
        "    #        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "    if INSTALL_GFPGAN:\n",
        "        if IMAGE_UPSCALER == \"GFPGAN\":\n",
        "            stt = int(time.time())\n",
        "            clean_env()\n",
        "            print(':sparkle: GFPGAN Face Restoration... ')\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/GFPGAN')\n",
        "            print(subprocess.run(f'python inference_gfpgan.py -i {filedir} -o {OUTDIR} -v 1.3 -s {UPSCALE_AMOUNT} --bg_upsampler realesrgan'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('GFPGAN Image:')\n",
        "                display(Image.open(f'{OUTDIR}/restored_imgs/{filename}'))\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'GFPGAN B: {(i+1)} I: {(iteration+1)}', Image.open(f'{OUTDIR}/restored_imgs/{filename}'))\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            print(f'Moving enhanced image to {OUTDIR}')\n",
        "            if not KEEP_ONLY_FINAL_IMAGE:\n",
        "                shutil.move(f'{OUTDIR}/restored_imgs/{filename}', f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "            else:\n",
        "                shutil.move(f'{OUTDIR}/restored_imgs/{filename}', f'{filedir}')\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'GFPGAN Face Restoration completed in {fnt}')\n",
        "            clean_env()\n",
        "    else:\n",
        "        print(\":warning: GFPGAN is not installed! Please check \\'INSTALL_GFPGAN\\' and run the environment setup again.\")\n",
        "\n",
        "    if INSTALL_ESRGAN:\n",
        "        if IMAGE_UPSCALER == \"Enhanced Real-ESRGAN\":\n",
        "            stt = int(time.time())\n",
        "            clean_env()\n",
        "            print(':multiply: Real-ESRGAN Upscaling... ')\n",
        "            print(f'For Real-ESRGAN upscaling only 2, 4, and 8 are supported. Choosing the nearest Value: {nearest_value}')\n",
        "            UPSCALE_AMOUNT = nearest_value\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            sr_image = upscale(image, UPSCALE_AMOUNT, ESRGAN_MODE)\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('Real-ESRGAN Image:')\n",
        "                display(sr_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Real-ESRGAN B: {(i+1)} I: {(iteration+1)}', sr_image)\n",
        "            if not KEEP_ONLY_FINAL_IMAGE:\n",
        "                sr_image.save(f'{OUTDIR}/{str(epoch_time)}_scale_{SCALE}_steps_{STEPS}_seed_{SEED}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "            else:\n",
        "                sr_image.save(filedir)\n",
        "            sr_image.close()\n",
        "            del sr_image\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'Enhanced Real-ESRGAN completed in {fnt}')\n",
        "            clean_env()\n",
        "    else:\n",
        "        print(\":warning: Real-ESRGAN is not installed! Please check \\'INSTALL_ESRGAN\\' and run the environment setup again.\")\n",
        "\n",
        "\n",
        "    if INSTALL_GFPGAN and INSTALL_ESRGAN:\n",
        "        if IMAGE_UPSCALER == \"GFPGAN + Enhanced ESRGAN\":\n",
        "            stt = int(time.time())\n",
        "            clean_env()\n",
        "            # GFPGAN\n",
        "            print(':sparkle: GFPGAN Face Restoration... ')\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/GFPGAN')\n",
        "            print(subprocess.run(f'python inference_gfpgan.py -i {filedir} -o {OUTDIR} -v 1.3 -s 1 --bg_upsampler realesrgan'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            shutil.move(f'{OUTDIR}/restored_imgs/{filename}', f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "            \n",
        "            # Real-ESRGAN\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN')\n",
        "            enhanced_image = Image.open(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "            if SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN:\n",
        "                enhanced_image = enhanced_image.resize((WIDTH,HEIGHT))\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('GFPGAN Image:')\n",
        "                display(enhanced_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'GFPGAN B: {(i+1)} I: {(iteration+1)}', enhanced_image)\n",
        "            print(\":multiply: Real-ESRGAN Upscaling... \")\n",
        "            if UPSCALE_AMOUNT not in [2,4,8]:\n",
        "              UPSCALE_AMOUNT = nearest_value\n",
        "              print(f'For Real-ESRGAN upscaling only 2, 4, and 8 are supported. Choosing the nearest Value: {nearest_value}')\n",
        "            sr_image = upscale(enhanced_image, UPSCALE_AMOUNT, ESRGAN_MODE)\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('Real-ESRGAN Image:')\n",
        "                display(sr_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Real-ESRGAN B: {(i+1)} I: {(iteration+1)}', sr_image)\n",
        "            if not KEEP_ONLY_FINAL_IMAGE:\n",
        "                sr_image.save(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "            else:\n",
        "                os.remove(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "                sr_image.save(filedir)\n",
        "            sr_image.close()\n",
        "            del sr_image\n",
        "            enhanced_image.close()\n",
        "            del enhanced_image\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'GFPGAN + Real-ESRGAN completed in {fnt}')\n",
        "            clean_env()\n",
        "    else:\n",
        "        if not INSTALL_GFPGAN:\n",
        "            print(\":warning: GFPGAN is not installed! Please check \\'INSTALL_GFPGAN\\' and run the environment setup again.\")\n",
        "        if not INSTALL_ESRGAN:\n",
        "            print(\":warning: Real-ESRGAN is not installed! Please check \\'INSTALL_ESRGAN\\' and run the environment setup again.\")\n",
        "\n",
        "    if INSTALL_CODEFORMER:\n",
        "        if IMAGE_UPSCALER == \"CodeFormer\":\n",
        "            stt = int(time.time())\n",
        "            fidelity = float(CODEFORMER_FIDELITY)\n",
        "            if fidelity is 0:\n",
        "                fidelity = '0.0'\n",
        "            clean_env()\n",
        "            print(\":sparkle: CodeFormer Face Restoration... \")\n",
        "            # It was behaving weird, hence why I am doing this the weird way\n",
        "            print(subprocess.run(f'cp {filedir} {STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp/'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer')\n",
        "            print(subprocess.run(f'python inference_codeformer.py --w {fidelity} --test_path {STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp --upscale {CODEFORMER_UPSCALE_AMOUNT} --bg_upsampler realesrgan'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "            os.remove(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp/{filename}')\n",
        "            cftarget = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{CODEFORMER_UPSCALE_AMOUNT}.png' if not KEEP_ONLY_FINAL_IMAGE else filedir\n",
        "            if not KEEP_ONLY_FINAL_IMAGE:\n",
        "                shutil.copyfile(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer/results/temp_{fidelity}/final_results/{filename}', cftarget)\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}')\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('CodeFormer Image:')\n",
        "                display(Image.open(cftarget))\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'CodeFormer B: {(i+1)} I: {(iteration+1)}', Image.open(cftarget))\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'CodeFormer Face Restoration completed in {fnt}')\n",
        "            clean_env()\n",
        "    else:\n",
        "        print(\":warning: CodeFormer is not installed! Please check \\'INSTALL_CODEFORMER\\' and run the environment setup again.\")\n",
        "\n",
        "\n",
        "    if INSTALL_CODEFORMER and INSTALL_ESRGAN:\n",
        "        if IMAGE_UPSCALER == \"CodeFormer + Enhanced ESRGAN\":\n",
        "            stt = int(time.time())\n",
        "            fidelity = float(CODEFORMER_FIDELITY)\n",
        "            if fidelity is 0:\n",
        "                fidelity = '0.0'\n",
        "            clean_env()\n",
        "            # CodeFormer\n",
        "            print(\":sparkle: CodeFormer Face Restoration... \")\n",
        "            print(subprocess.run(f'cp {filedir} {STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp/'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer')\n",
        "            print(subprocess.run(f'python inference_codeformer.py --w {fidelity} --test_path {STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp --bg_upsampler realesrgan'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "            os.remove(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp/{filename}')\n",
        "            cftarget = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{CODEFORMER_UPSCALE_AMOUNT}.png' if not KEEP_ONLY_FINAL_IMAGE else filedir\n",
        "            shutil.copyfile(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer/results/temp_{fidelity}/final_results/{filename}', cftarget)\n",
        "            \n",
        "            # Real-ESRGAN\n",
        "            os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN')\n",
        "            enhanced_image = Image.open(cftarget)\n",
        "            if SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN:\n",
        "                enhanced_image = enhanced_image.resize((WIDTH,HEIGHT))\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('CodeFormer Image:')\n",
        "                display(enhanced_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'CodeFormer B: {(i+1)} I: {(iteration+1)}', enhanced_image)\n",
        "            print(\":multiply: Real-ESRGAN Upscaling... \")\n",
        "            if UPSCALE_AMOUNT not in [2,4,8]:\n",
        "              UPSCALE_AMOUNT = nearest_value\n",
        "              print(f'For Real-ESRGAN upscaling only 2, 4, and 8 are supported. Choosing the nearest Value: {nearest_value}')\n",
        "            sr_image = upscale(enhanced_image, UPSCALE_AMOUNT, ESRGAN_MODE)\n",
        "            if USE_BASIC_IMAGE_DISPLAY:\n",
        "                print('Real-ESRGAN Image:')\n",
        "                display(sr_image)\n",
        "            else:\n",
        "                displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Real-ESRGAN B: {(i+1)} I: {(iteration+1)}', sr_image)\n",
        "            if not KEEP_ONLY_FINAL_IMAGE:\n",
        "                sr_image.save(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "            else:\n",
        "                sr_image.save(filedir)\n",
        "            sr_image.close()\n",
        "            del sr_image\n",
        "            enhanced_image.close()\n",
        "            del enhanced_image\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f'CodeFormer + Real-ESRGAN completed in {fnt}')\n",
        "            clean_env()\n",
        "    else:\n",
        "        if not INSTALL_CODEFORMER:\n",
        "            print(\":warning: CodeFormer is not installed! Please check \\'INSTALL_CODEFORMER\\' and run the environment setup again.\")\n",
        "        if not INSTALL_ESRGAN:\n",
        "            print(\":warning: Real-ESRGAN is not installed! Please check \\'INSTALL_ESRGAN\\' and run the environment setup again.\")\n",
        "\n",
        "   \n",
        "    if INTERROGATE_DIFFUSION_IMAGE and not SKIP_DIFFUSION_RUN:\n",
        "        clean_env()\n",
        "        do_interrogate(interrogate_image.copy())\n",
        "        interrogate_image.close()\n",
        "        del interrogate_image\n",
        "        scraper.updateGlobals(globals())\n",
        "        scraper.scrape('clip_interrogator')\n",
        "\n",
        "    if SAVE_SETTING_FILE:\n",
        "        epoch_time = int(time.time())\n",
        "        with open(f'{OUTDIR}/{epoch_time}_settings.txt', 'w') as file:\n",
        "            file.write(json.dumps(scraper.params, indent=4))\n",
        "\n",
        "    image.close()\n",
        "    del image\n",
        "    if KEEP_ONLY_FINAL_IMAGE:\n",
        "        if os.path.exists(f'{OUTDIR}/cmp'):\n",
        "            shutil.rmtree(f'{OUTDIR}/cmp')\n",
        "        if os.path.exists(f'{OUTDIR}/cropped_faces'):\n",
        "            shutil.rmtree(f'{OUTDIR}/cropped_faces')\n",
        "        if os.path.exists(f'{OUTDIR}/restored_faces'):\n",
        "            shutil.rmtree(f'{OUTDIR}/restored_faces')\n",
        "        if os.path.exists(f'{OUTDIR}/restored_imgs'):\n",
        "            shutil.rmtree(f'{OUTDIR}/restored_imgs')\n",
        "\n",
        "    if CLEAR_LOG_BETWEEN_ITERATIONS and not USE_BASIC_IMAGE_DISPLAY:\n",
        "        clearOutputArea(i, iteration);\n",
        "\n",
        "# End Diffuse Function\n",
        "\n",
        "if SKIP_DIFFUSION_RUN:\n",
        "    print(f':gear: Skipping Diffusion Run to Process Images...')\n",
        "    PROMPT = 'None'\n",
        "    PROMPT_FILE = ''\n",
        "    NUM_ITERS = 1\n",
        "else:\n",
        "    # Setup Prompts\n",
        "    if PROMPT.lower() in [None, '', 'none'] and PROMPT_FILE in [None, '', 'none']:\n",
        "        raise Exception(\"PROMPT and PROMPT_FILE are empty! You need to provide a PROMPT or PROMPT_FILE!\")\n",
        "\n",
        "PROMPTS = []\n",
        "if PROMPT_FILE not in ['','none']:\n",
        "    try:\n",
        "        with open(PROMPT_FILE, \"r\") as f:\n",
        "            PROMPTS = f.read().splitlines()\n",
        "    except OSError as e:\n",
        "        raise e\n",
        "        \n",
        "# Insert prompt string first\n",
        "if PROMPT not in ['', 'none']:\n",
        "    PROMPTS.insert(0, PROMPT)\n",
        "\n",
        "#Get corrected sizes\n",
        "WX = (WIDTH//64)*64;\n",
        "HY = (HEIGHT//64)*64;\n",
        "if int(WX) != int(WIDTH) or int(HY) != int(HEIGHT):\n",
        "    print(f':warning: Changing output size to {WX}x{HY}. Dimensions must by multiples of 64.')\n",
        "    WIDTH = WX\n",
        "    HEIGHT = HY\n",
        "\n",
        "# Setup init_iamge\n",
        "inits = None\n",
        "masks = None\n",
        "init = None\n",
        "mask = None\n",
        "if INIT_IMAGE.lower() not in [None, '', 'none']:\n",
        "    print(\":hourglass_not_done: Searching for init images...\")\n",
        "    if INIT_IMAGE.lower().startswith('http://') or INIT_IMAGE.lower().startswith('https://'):\n",
        "        inits = INIT_IMAGE\n",
        "    else:\n",
        "        inits = getInitImages(INIT_IMAGE, INIT_FILTERS, True)\n",
        "    if inits is not None:\n",
        "        pipe_type = 'img2img'\n",
        "    else:\n",
        "        print(f\":WARNING: No valid image(s) found in {INIT_IMAGE}. Switching to default Text-to-Image run...\")\n",
        "        pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "\n",
        "else:\n",
        "    pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "    \n",
        "if INIT_MASK.lower() not in [None, '', 'none']:\n",
        "    print(\":hourglass_not_done: Searching for mask images...\")\n",
        "    if INIT_MASK.lower().startswith('http://') or INIT_MASK.lower().startswith('https://'):\n",
        "        masks = [INIT_MASK]\n",
        "    else:\n",
        "        masks = getInitImages(INIT_MASK, INIT_FILTERS, True)\n",
        "    if masks is not None:\n",
        "        pipe_type = 'inpaint'\n",
        "    else:\n",
        "        if inits is None:\n",
        "            print(f\":WARNING: No valid mask image(s) found in {INIT_MASK}. Switching to default Text-to-Image run...\")\n",
        "            pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "        else:\n",
        "            print(f\":WARNING: No valid mask image(s) found in {INIT_MASK}. Switching to default Image-to-Image run...\")\n",
        "            pipe_type = 'img2img'\n",
        "\n",
        "# Check if there are images before skipping diffusion\n",
        "if SKIP_DIFFUSION_RUN and inits is None:\n",
        "    SystemExit(\":warning: INIT_IMAGE must be defined with valid image(s) to skip diffusion run!\")\n",
        "\n",
        "# Initiate non-cached pipelines\n",
        "if not CACHE_PIPELINES and not SKIP_DIFFUSION_RUN:\n",
        "    print(\"Setting up diffusion model pipeline...\")\n",
        "    try:\n",
        "        if pipe and pipe is not None:\n",
        "            print(\":computer_disk: Pipeline already in memory. Starting diffusion environment...\\n\")\n",
        "    except NameError:\n",
        "        pipe = setup_pipes(pipe_type, MODEL_ID, model_cache)\n",
        "        pass\n",
        "    if ( last_diffusion_filedir is None \n",
        "            and inits is None \n",
        "            and type(pipe) is not StableDiffusionPipeline ):\n",
        "        print(\"Pipeline in memory is is a img2img-type pipeline, but no INIT_IMAGE or Evolution is defined.\")\n",
        "        pipe = setup_pipes('lowvram', MODEL_ID, model_cache) if LOW_VRAM_PATCH else setup_pipes('default', MODEL_ID, model_cache)\n",
        "        pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "    if pipe_type is not last_pipe_type:\n",
        "        pipe = setup_pipes(pipe_type, MODEL_ID, model_cache)\n",
        "    if ENABLE_ATTENTION_SLICES:\n",
        "        print(':gear: Attention Slices Enabled.')\n",
        "        pipe.enable_attention_slicing()\n",
        "        #optimize_attention(pipe.unet)\n",
        "    else:\n",
        "        print(':gear: Attention Slices Disabled.')\n",
        "        pipe.disable_attention_slicing()\n",
        "    print(':check_mark_button: Pipeline setup complete.')\n",
        "\n",
        "last_pipe_type = pipe_type\n",
        "\n",
        "with torch.no_grad():\n",
        "    with precision_scope(\"cuda\"):\n",
        "\n",
        "        # Hack in Image List Support\n",
        "        DO = None\n",
        "        if type(inits) is list:\n",
        "            ITERATE_THIS = inits\n",
        "            DO = 'inits'\n",
        "        else:\n",
        "            ITERATE_THIS = PROMPTS\n",
        "            DO = 'prompts'\n",
        "\n",
        "        i = 0\n",
        "        for pi in ITERATE_THIS: # Replace PROMPTS with ITERATE_THIS switch\n",
        "\n",
        "            if DO is 'inits':\n",
        "                init = pi\n",
        "                if i > len(PROMPTS)-1:\n",
        "                    pi = PROMPTS[-1]\n",
        "                else:\n",
        "                    pi = PROMPTS[i]\n",
        "                if masks:\n",
        "                    if i > len(masks)-1:\n",
        "                        mask = masks[-1]\n",
        "                    else:\n",
        "                        mask = masks[i]\n",
        "                else:\n",
        "                    mask = None\n",
        "            elif DO is 'prompts':\n",
        "                if inits is not None:\n",
        "                    init = inits\n",
        "                if masks:\n",
        "                    if type(masks) is list:\n",
        "                        if i > len(masks)-1:\n",
        "                            mask = masks[-1]\n",
        "                        else:\n",
        "                            mask = masks[i]\n",
        "                    else:\n",
        "                        mask = masks\n",
        "                else:\n",
        "                    mask = None\n",
        "            if init:    \n",
        "                from PIL import ImageOps\n",
        "                init = Image.open(fetch(init)).convert(\"RGB\")\n",
        "                #init = ImageOps.exif_transpose(init)\n",
        "                init = init.resize((WIDTH,HEIGHT))\n",
        "                original_init = init.copy()\n",
        "                #init = preprocess(init)\n",
        "            if mask:    \n",
        "                from PIL import ImageOps\n",
        "                mask = Image.open(fetch(mask)).convert(\"RGB\")\n",
        "                #mask = ImageOps.exif_transpose(mask)\n",
        "                mask = mask.resize((WIDTH,HEIGHT))\n",
        "                original_mask = mask.copy()\n",
        "                #mask = preprocess(mask)\n",
        "\n",
        "            # Define Run Prompt\n",
        "            if NEW_NSP_ON_ITERATION is not True:\n",
        "                PROMPT = nsp_parse(pi)\n",
        "\n",
        "            for iteration in range(NUM_ITERS):\n",
        "\n",
        "                # Define Iteration Prompt\n",
        "                if NEW_NSP_ON_ITERATION:\n",
        "                    PROMPT = nsp_parse(pi)\n",
        "\n",
        "                try:\n",
        "\n",
        "                    diffuse_run()\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if 'out of memory' in str(e):\n",
        "                        print(f\"\\u001b[31m\\u001b[1m\\u001b[4mCRITICAL ERROR\\u001b[0m: {gpu_name} ran out of memory! If this error persists, the GPU may have crashed, and requires a disconnect/re-run.\")\n",
        "                        pass\n",
        "                    else:\n",
        "                        raise e\n",
        "                except KeyboardInterrupt as e:\n",
        "                    raise SystemExit('\\33[33mExecution interrupted by user.\\33[0m')\n",
        "                except Exception as e:\n",
        "                    raise e\n",
        "                finally:\n",
        "                    clean_env()\n",
        "                    \n",
        "            i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <a name=\"cleanenv\"><font color=\"orange\">**Clean Environment Up**</font></a>\n",
        "#@markdown <font size=\"3\">**Soft Reset** the environment by deleting pipes, models, and image handlers from memory.<br><br>\n",
        "#@markdown **Note:** Before using this cell, give a minute for the system itself to flush some stuff. This will give a higher chance of this function working.<br>\n",
        "#@markdown **Note 2:** Sometimes you'll get a persistent OOM bug when the GPU has been unallocated from your session. This is common with the new (09/2022) Free Colab Sessions</font>\n",
        "\n",
        "try:\n",
        "    del pipe; del midas; del transform; del prediction; del input_batch; del depth; del depth_image; del image; del sr_image; del enhanced_image; del img; del init; del original_init\n",
        "except NameError:\n",
        "    pass\n",
        "finally:\n",
        "    clean_env(True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RjZhn2vwEydT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"default\">**Menu**</font>\n",
        "- <a href=\"#changelog\">**Change Log**</a>\n",
        "- <a href=\"#gpustatus\">**Check GPU Status**</a>\n",
        "- #### <a href=\"#setupenv\">**Setup Environment**</a>\n",
        " - <a href=\"#googledrive\">**Google Drive Options**</a>\n",
        " - <a href=\"#optionalfeats\">**Install Optional Features**</a>\n",
        " - <a href=\"#otherinstall\">**Other Install Options**</a>\n",
        "- #### <a href=\"#settingsdiffuse\">**Settings & Diffuse**</a>\n",
        " - <a href=\"#promptsetup\">**Prompt Setup**</a>\n",
        " - <a href=\"#initsetup\">**Init Image Setup**</a>\n",
        " - <a href=\"#diffusionsettings\">**Diffusion Settings**</a>\n",
        " - <a href=\"#upscalers\">**Upscaling Setup**</a>\n",
        " - <a href=\"#imageprocessors\">**Image Processing Setup**</a>\n",
        "   - <a href=\"#sharpen\">**Sharpen Image**</a>\n",
        "   - <a href=\"#kromo\">**Kromo Chromatic Aberration**</a>\n",
        "   - <a href=\"#median\">**Median Filter Image**</a>\n",
        "   - <a href=\"#midas\">**MiDaS Depth Export**</a>\n",
        "   - <a href=\"#fdof\">**Fake Depth of Field Filter**</a>\n",
        "   - <a href=\"#tileable\">**Tileable Seamless Image**</a>\n",
        " - <a href=\"#clipinterrogator\">**CLIP Interrogator**</a>\n",
        " - <a href=\"#othersettings\">**Other Diffusion Settings**</a>\n",
        "- <a href=\"#cleanenv\">**Clean Environment Up**</a>"
      ],
      "metadata": {
        "id": "mOY91EzZ1nQH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}